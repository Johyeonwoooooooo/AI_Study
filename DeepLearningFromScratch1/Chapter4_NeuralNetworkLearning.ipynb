{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 : Neural Network Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 함수 loss function\n",
    "\n",
    "## 오차 제곱합\n",
    "\n",
    "$ {1 \\over 2}  \\displaystyle\\sum_{y=y0}^{yn}{(y - t) ^ 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 엔트로피 오차\n",
    "\n",
    "$ E = - \\displaystyle\\sum_{y=y0}^{yn}{tlogy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "# delta를 더하는 이유? -> y = 0 일 경우엔 log에 들어가면 에러가 난다. 이를 방지하기 위해 매우 작은 수를 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.11809565095832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.0, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.6]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mini-batch learning\n",
    "\n",
    "mini batch는 왜 사용할까?\n",
    "\n",
    "-> 훈련 데이터가 많으면 많을 수록 iteration의 시간이 오래 걸림, loss function의 계산에도 부하가 옴\n",
    "\n",
    "-> 데이터의 일부를 추려 근사치로 이용하도록 함\n",
    "\n",
    "장점\n",
    "\n",
    "빠른 시간 내에 적당히 정확한 경로를 찾아낼 수 있음\n",
    "\n",
    "단점\n",
    "\n",
    "데이터 전체의 경향을 파악하지 않아 정확하지 않음\n",
    "\n",
    "**적당히 빠른 길을 찾기 위해 사용됨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "x_train.shape\n",
    "t_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "\n",
    "print(x_batch.shape[0])\n",
    "print(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # flatten answer \n",
    "        y = y.reshape(1, y.size) # flatten output \n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y+1e-7)) / batch_size # entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nt -> 정답이고 batch_size -> y 갯수로 설정함\\nnp.arange(batch_size)로 0~9 까지 생성시킴\\nt -> 정답 index 결국 y[0~9 , 정답 num]의 값을 가져와서 log 하는거랑 같음\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # flatten answer \n",
    "        y = y.reshape(1, y.size) # flatten output\n",
    "\n",
    "    batch_size = y.shape[0] \n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "'''\n",
    "t -> 정답이고 batch_size -> y 갯수로 설정함\n",
    "np.arange(batch_size)로 0~9 까지 생성시킴\n",
    "t -> 정답 index 결국 y[0~9 , 정답 num]의 값을 가져와서 log 하는거랑 같음\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function을 propagation의 지표로 사용하는 이유\n",
    "\n",
    "정확도를 기준으로 학습시키면 좋을 것 같지만, 정확도로 학습시키면 시킬수록 미분값이 0이 됨.\n",
    "\n",
    "즉 학습이 이루어지지 않음\n",
    "\n",
    "그렇기 때문에 손실함수를 사용함\n",
    "\n",
    "ex) chapter3 에서의 계단함수와 시그모이드 함수 비교\n",
    "    계단함수는 대부분의 구간에서 미분값이 0, 시그모이드 함수는 미분값이 거의 항상 변함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_diff_badcase(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h) - f(x)) / h\n",
    "\n",
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 미분 식이 Bad case인 이유\n",
    "\n",
    "1. np.float32(h)를 했을 때 0이 나옴. 즉, 너무 작은 값을 사용하려하다 보니\n",
    "\n",
    "    오히려 0으로 취급되어서 오류를 발생시킬 수 도 있음 (반올림 오차 rounding error)\n",
    "\n",
    "2. 미분은 x위치의 함수의 기울기에 해당함. \n",
    "   \n",
    "   위 함수의 구현은 (x+h)와 x사이의 기울기에 해당하기 때문에 진정한 미분과는 거리가 있음.\n",
    "   \n",
    "   즉, h를 0으로 무한하게 좁히는것이 불가능하기 때문에 생기는 한계이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 중간차분법이 좋은 이유는 증명이 길기 때문에 아래 작성한 벨로그를 참고\n",
    "\n",
    "h = 1e-4 로 둔 이유는 casting 시 0.0이 되지 않으면서 가장 적은 오차를 내는 h가 1e-4로 알려져 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
