{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 : Neural Network Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 손실 함수 loss function\n",
    "\n",
    "## 오차 제곱합\n",
    "\n",
    "$ {1 \\over 2}  \\displaystyle\\sum_{y=y0}^{yn}{(y - t) ^ 2}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sum_squares_error(y, t):\n",
    "    return 0.5 * np.sum((y-t)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09750000000000003"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5975"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]\n",
    "sum_squares_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 교차 엔트로피 오차\n",
    "\n",
    "$ E = - \\displaystyle\\sum_{y=y0}^{yn}{tlogy}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y,t):\n",
    "    delta = 1e-7\n",
    "    return -np.sum(t * np.log(y + delta))\n",
    "\n",
    "# delta를 더하는 이유? -> y = 0 일 경우엔 log에 들어가면 에러가 난다. 이를 방지하기 위해 매우 작은 수를 더함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.510825457099338"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.11809565095832"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
    "y = [0.1, 0.05, 0.0, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.6]\n",
    "cross_entropy_error(np.array(y), np.array(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mini-batch learning\n",
    "\n",
    "mini batch는 왜 사용할까?\n",
    "\n",
    "-> 훈련 데이터가 많으면 많을 수록 iteration의 시간이 오래 걸림, loss function의 계산에도 부하가 옴\n",
    "\n",
    "-> 데이터의 일부를 추려 근사치로 이용하도록 함\n",
    "\n",
    "장점\n",
    "\n",
    "빠른 시간 내에 적당히 정확한 경로를 찾아낼 수 있음\n",
    "\n",
    "단점\n",
    "\n",
    "데이터 전체의 경향을 파악하지 않아 정확하지 않음\n",
    "\n",
    "**적당히 빠른 길을 찾기 위해 사용됨**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "x_train.shape\n",
    "t_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "train_size = x_train.shape[0]\n",
    "batch_size = 10\n",
    "batch_mask = np.random.choice(train_size, batch_size)\n",
    "x_batch = x_train[batch_mask]\n",
    "t_batch = t_train[batch_mask]\n",
    "\n",
    "\n",
    "print(x_batch.shape[0])\n",
    "print(x_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # flatten answer \n",
    "        y = y.reshape(1, y.size) # flatten output \n",
    "\n",
    "    batch_size = y.shape[0]\n",
    "    return -np.sum(t * np.log(y+1e-7)) / batch_size # entropy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nt -> 정답이고 batch_size -> y 갯수로 설정함\\nnp.arange(batch_size)로 0~9 까지 생성시킴\\nt -> 정답 index 결국 y[0~9 , 정답 num]의 값을 가져와서 log 하는거랑 같음\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cross_entropy_error(y, t):\n",
    "    if y.ndim == 1:\n",
    "        t = t.reshape(1, t.size) # flatten answer \n",
    "        y = y.reshape(1, y.size) # flatten output\n",
    "\n",
    "    batch_size = y.shape[0] \n",
    "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size\n",
    "'''\n",
    "t -> 정답이고 batch_size -> y 갯수로 설정함\n",
    "np.arange(batch_size)로 0~9 까지 생성시킴\n",
    "t -> 정답 index 결국 y[0~9 , 정답 num]의 값을 가져와서 log 하는거랑 같음\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss function을 propagation의 지표로 사용하는 이유\n",
    "\n",
    "정확도를 기준으로 학습시키면 좋을 것 같지만, 정확도로 학습시키면 시킬수록 미분값이 0이 됨.\n",
    "\n",
    "즉 학습이 이루어지지 않음\n",
    "\n",
    "그렇기 때문에 손실함수를 사용함\n",
    "\n",
    "ex) chapter3 에서의 계단함수와 시그모이드 함수 비교\n",
    "    계단함수는 대부분의 구간에서 미분값이 0, 시그모이드 함수는 미분값이 거의 항상 변함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def numerical_diff_badcase(f, x):\n",
    "    h = 1e-50\n",
    "    return (f(x+h) - f(x)) / h\n",
    "\n",
    "np.float32(1e-50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 미분 식이 Bad case인 이유\n",
    "\n",
    "1. np.float32(h)를 했을 때 0이 나옴. 즉, 너무 작은 값을 사용하려하다 보니\n",
    "\n",
    "    오히려 0으로 취급되어서 오류를 발생시킬 수 도 있음 (반올림 오차 rounding error)\n",
    "\n",
    "2. 미분은 x위치의 함수의 기울기에 해당함. \n",
    "   \n",
    "   위 함수의 구현은 (x+h)와 x사이의 기울기에 해당하기 때문에 진정한 미분과는 거리가 있음.\n",
    "   \n",
    "   즉, h를 0으로 무한하게 좁히는것이 불가능하기 때문에 생기는 한계이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_diff(f, x):\n",
    "    h = 1e-4\n",
    "    return (f(x+h) - f(x-h)) / (2*h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "위 중간차분법이 좋은 이유는 증명이 길기 때문에 아래 작성한 벨로그를 참고\n",
    "\n",
    "https://velog.io/@hyunwoo02031/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EC%88%98%EC%B9%98%EB%AF%B8%EB%B6%84-%EC%B0%A8%EB%B6%84%EB%B2%95%EC%97%90-%EB%94%B0%EB%A5%B8-%EC%98%A4%EC%B0%A8\n",
    "\n",
    "h = 1e-4 로 둔 이유는 casting 시 0.0이 되지 않으면서 가장 적은 오차를 내는 h가 1e-4로 알려져 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_1(x):\n",
    "    return 0.01 * x ** 2 + 0.1 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAioAAAGwCAYAAACHJU4LAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABBZElEQVR4nO3deVhU9eLH8c+wuwBuICCIuC+4b6mVlaaZlaaVmZWaLZYt5r3ltd9t8XZvtt2u1e2aLW5paZta2qolmrvgghvugAqoqAyLDDBzfn+YlAUKKJxZ3q/n4XmamTPD53hmOJ/OfM/3WAzDMAQAAOCEvMwOAAAAUBqKCgAAcFoUFQAA4LQoKgAAwGlRVAAAgNOiqAAAAKdFUQEAAE7Lx+wAl8LhcOjo0aMKDAyUxWIxOw4AACgDwzCUnZ2tiIgIeXld+JiJSxeVo0ePKioqyuwYAACgAlJTUxUZGXnBZVy6qAQGBko6u6JBQUEmpwEAAGVhtVoVFRVVvB+/EJcuKue+7gkKCqKoAADgYsoybIPBtAAAwGlRVAAAgNOiqAAAAKdFUQEAAE6LogIAAJwWRQUAADgtigoAAHBapheVI0eO6O6771bdunVVrVo1tW3bVps2bTI7FgAAcAKmTvh26tQp9erVS9dee62+/fZbhYSEaO/evapdu7aZsQAAgJMwtai88sorioqK0syZM4vvi4mJMTERAABwJqZ+9fPVV1+pS5cuuv322xUaGqqOHTvq/fffL3V5m80mq9V63g8AAHBfphaVAwcOaNq0aWrWrJm+//57Pfzww3r88cc1e/bsEpefMmWKgoODi3+4cjIAAO7NYhiGYdYv9/PzU5cuXbRmzZri+x5//HFt3LhRa9eu/dPyNptNNput+Pa5qy9mZWVxUUIAAC6z5bsydG2LUHl5XfzigeVhtVoVHBxcpv23qUdUwsPD1bp16/Pua9WqlVJSUkpc3t/fv/hKyVwxGQCAyvPJhhSNmb1JD82Nl8Nh2jENc4tKr169lJSUdN59e/bsUXR0tEmJAADApkMn9dzi7ZKk9pHBl/2ISnmYWlSefPJJrVu3Ti+99JL27dunjz/+WO+9957GjRtnZiwAADxWWtYZjZ2boEK7oRvbhmnctU1NzWNqUenatasWLlyoTz75RLGxsXrxxRc1depUjRgxwsxYAAB4pPxCu8Z+FK8TOTa1DAvUa7e1l8Vi3tEUyeTBtJeqPINxAABA6QzD0F8+26ovE46oVnVfff3olYqqU71SfpfLDKYFAADOYcbqQ/oy4Yi8vSx6565OlVZSyouiAgCAh1u197j+tXSnJOmZG1upV9N6Jif6DUUFAAAPduB4jsbNS5DDkIZ2itR9vRqZHek8FBUAADyUNb9Q98/ZJGt+kTo1rKWXhsSaPnj2jygqAAB4ILvD0GMfb9aB47kKDw7Qu/d0lr+Pt9mx/oSiAgCAB3rlu92K23NcAb5eev/eLgoNDDA7UokoKgAAeJjP4w/rvZUHJEmv395esQ2CTU5UOooKAAAeJCHllJ75MlGS9Nh1TXVTuwiTE10YRQUAAA+RlnVGD86JV4HdoX6t6+vJvs3NjnRRFBUAADzAmQK7Hpzz2/T4/xnWwdSLDZYVRQUAADdnGIae/mKbEo9kqU4NP71/bxfV8PcxO1aZUFQAAHBz7/y8T19vPSofL4v+N8J5pscvC4oKAABu7Icd6Xr9hz2SpH8MitUVjeuanKh8KCoAALip3elWjV+wRZJ0b49o3dW9obmBKoCiAgCAGzqZW6D7Z29SXoFdPZvU1bM3tTY7UoVQVAAAcDMFRQ49PDdeh0+dUXTd6nrnrk7y9XbNXb5rpgYAAKWa/PUOrT94UjX9ffT+vV1Uu4af2ZEqjKICAIAbmbP2kOatT5HFIr15Zwc1rx9odqRLQlEBAMBNxO05rslf75QkPdW/hfq0qm9yoktHUQEAwA3szcjWo/MSZHcYGtKpgR7u3cTsSJcFRQUAABeXmWPTfbM3KttWpK6NamvKkLayWJx/evyyoKgAAODCbEV2jZ0br9STZ9SwTnVNv6eL/H28zY512VBUAABwUYZhaNKXidp46JQCA3w0Y1QX1XHhM3xKQlEBAMBF/W/Ffn2ZcETeXha9c1cnNQ117TN8SkJRAQDABX23PU2vfZ8kSXrhlja6unmIyYkqB0UFAAAXk3g4q/gaPqN6NtI9V0SbG6gSUVQAAHAh6Vn5un/ORuUXOtS7eYj+PrCV2ZEqFUUFAAAXkVdQpDGzNyrDalPz+jX19l0d5eOi1/ApK/deOwAA3ITDYejJBVu046hVdWv46cORXRUU4Gt2rEpHUQEAwAW89kOSvt+RIT9vL713b2dF1aludqQqQVEBAMDJfbYpVdNW7JckvXpbO3WOrmNyoqpDUQEAwImtP5CpZxYmSpIeu66pBndsYHKiqkVRAQDASSVn5mrs3HgV2g0NbBuuJ/s2NztSlaOoAADghLLyCnXfrI06lVeo9pHBev329vLyco8LDZYHRQUAACdTUOTQ2Lnx2n88V+HBAXr/3i6q5uc+FxosD4oKAABO5NyFBtceyFRNfx/NGNVVoUEBZscyDUUFAAAn8vZP+/RFwuGzFxoc0UmtwoPMjmQqigoAAE5i0eYjeuPHPZKkFwfFqrebXmiwPCgqAAA4gfUHMvX059skSQ9d3Vh3dW9ociLnQFEBAMBk+4/n6MGP4lVgd+jGtmGaeENLsyM5DYoKAAAmysyxafTMjco6U6iODWvpjTs6eORpyKWhqAAAYJL8QrsemLNJKSfzFFWnmt6/t4sCfD3zNOTSUFQAADCBw2HoL59uVULKaQVX89XMUd1Ur6a/2bGcDkUFAAATvPp9kpYmpsnX26Lp93RW09CaZkdyShQVAACq2CcbUvRu3G9XQ76icV2TEzkvigoAAFUobs9x/X3RdknS+L7NdGvHSJMTOTdTi8oLL7wgi8Vy3k/LlpySBQBwT7vSrBo3L0F2h6EhnRroiT7NzI7k9HzMDtCmTRstW7as+LaPj+mRAAC47I6ePqPRMzcqx1akKxrX0ctD2sli4TTkizG9Ffj4+CgsLMzsGAAAVJqsM4UaNXOD0q35ahpaU9Pv7iI/H0ZflIXp/0p79+5VRESEGjdurBEjRiglJaXUZW02m6xW63k/AAA4M1uRXWM/iteejByFBvpr1uiuCq7ua3Ysl2FqUenevbtmzZql7777TtOmTdPBgwd11VVXKTs7u8Tlp0yZouDg4OKfqKioKk4MAEDZORyGJn6+TWsPZKqGn7dmju6qyNrVzY7lUiyGYRhmhzjn9OnTio6O1htvvKExY8b86XGbzSabzVZ822q1KioqSllZWQoK8uzLYAMAnM8r3+3WtBX75eNl0YxRXXU1V0OWdHb/HRwcXKb9t+ljVH6vVq1aat68ufbt21fi4/7+/vL3Z9Y+AIDz+2hdsqatODtXypQhbSkpFWT6GJXfy8nJ0f79+xUeHm52FAAAKuzHnRl6fvHZuVImXN9ct3dhqEJFmVpU/vrXvyouLk6HDh3SmjVrdOutt8rb21vDhw83MxYAABW2OeWUHvskQQ5DurNrlB67rqnZkVyaqV/9HD58WMOHD1dmZqZCQkJ05ZVXat26dQoJ4fAYAMD1HDqRqzGzNym/0KFrWoTon4NjmSvlEplaVObPn2/mrwcA4LLJzLFp5MwNOplboNgGQXrnrk7y8XaqERYuiX9BAAAu0ZkCu8bM3qTkzDxF1q6mGaO6qoa/U52v4rIoKgAAXAK7w9Bjn2zWltTTqlXdV7Pv66bQwACzY7kNigoAABVkGIZe+GqHlu3KkJ+Plz64t4uahNQ0O5ZboagAAFBB//1pnz5alyyLRZo6rIO6NKpjdiS3Q1EBAKAC5m9I0b9/3CNJeuHmNrqxLXOAVQaKCgAA5fTjzgw9szBRkjTu2iYa2bORuYHcGEUFAIByiE8+qUc/Pjuh2+2dI/XXfi3MjuTWKCoAAJTR3oxs3Tdrk2xFDl3XMlRThrRlQrdKRlEBAKAM0rLO6N4ZG5R1plAdG9ZiQrcqwr8wAAAXkZVXqJEzNigtK19NQmpoxsiuqubnbXYsj0BRAQDgAvIL7bp/zkbtychR/SB/zb6vm2rX8DM7lsegqAAAUIoiu0OPfbJZGw+dUmCAj2bf102RtaubHcujUFQAACiBYRh6dvEO/bjzt1lnW4YFmR3L41BUAAAowdRle/XJhhR5WaS37uyg7o3rmh3JI1FUAAD4g7nrkvXm8r2SpH8MitUNscw6axaKCgAAv/NNYpqeW7xdkvR4n2a6+4pokxN5NooKAAC/+mXvCY2fv0UOQxreLUpP9m1mdiSPR1EBAEDSltTTevCjTSqwOzQgNkz/HMyss86AogIA8Hj7jmVr1MwNyiuw68qm9TT1zg7y9qKkOAOKCgDAox0+lae7P9ig03mFah9VS9Pv6Sx/H2addRYUFQCAx8rMseneDzco3ZqvpqE1NXNUV9Xw9zE7Fn6HogIA8EjZ+YUaNXOjDpzIVYNa1fTRmG6qw9T4ToeiAgDwOPmFdj04J16JR7JUt4af5ozppvDgambHQgkoKgAAj1Jkd+jxTzZr7YFM1fT30azR3dQkpKbZsVAKigoAwGMYhqFJXybqh1+v3/P+vV3UNjLY7Fi4AIoKAMBjvPztbn0Wf1heFunt4R3VownX73F2FBUAgEd4N26/pq88IEl6eWg79W8TZnIilAVFBQDg9j7ZkKKXv90tSXrmxpa6o0uUyYlQVhQVAIBb+2rrUT2zMFGSNLZ3Ez14dROTE6E8KCoAALe1bGeGJizYIsOQRnRvqIk3tDA7EsqJogIAcEtr9p3QIx8nqMhh6NaODfTioFguMuiCKCoAALeTkHJK98/ZpIIih65vXV+v3dZOXlxk0CVRVAAAbmVXmlWjZvx2JeS3h3eUjze7O1fFlgMAuI0Dx3N0z4frZc0vUufo2nrv3s4K8OVKyK6MogIAcAtHTp/R3R+s14mcArUOD9KMUV1V3Y8rIbs6igoAwOUdy87XiPfX6WhWvhqH1NCcMd0UXM3X7Fi4DCgqAACXdjqvQPd+uEGHMvPUoFY1zbu/u+rV9Dc7Fi4TigoAwGXl2Io0auZG7U7PVmigvz5+oLvCg6uZHQuXEUUFAOCS8gvtemD2Jm1JPa1a1X019/7uiq5bw+xYuMwoKgAAl1NQ5NAj8xK09kCmavr7aPbobmpeP9DsWKgEFBUAgEspsjv0+Ceb9dPuY/L38dKHI7uofVQts2OhklBUAAAuw+4wNOHTrfpuR7r8vL30/r1d1L1xXbNjoRJRVAAALsHhMDTxi236autR+XhZ9L8RnXR18xCzY6GSUVQAAE7PMAw9u3i7Po8/LG8vi94e3lF9W9c3OxaqAEUFAODUDMPQi0t2ad76FFks0ht3tNeAtuFmx0IVcZqi8vLLL8tisWj8+PFmRwEAOAnDMPTq90masfqgJOmVIe00qEMDk1OhKjlFUdm4caOmT5+udu3amR0FAOBE3lq+T9NW7JckvTg4Vnd0jTI5Eaqa6UUlJydHI0aM0Pvvv6/atWubHQcA4CTejduv/yzbI0n6+8BWuueKaJMTwQymF5Vx48Zp4MCB6tu370WXtdlsslqt5/0AANzPzNUH9fK3uyVJT/VvofuvamxyIpjF1Otfz58/XwkJCdq4cWOZlp8yZYomT55cyakAAGb6eH2KJn+9U5L0+HVNNe7apiYngplMO6KSmpqqJ554QvPmzVNAQECZnjNp0iRlZWUV/6SmplZySgBAVfoi/rD+b1GiJOmhqxvryeubm5wIZrMYhmGY8YsXLVqkW2+9Vd7e3sX32e12WSwWeXl5yWaznfdYSaxWq4KDg5WVlaWgoKDKjgwAqESLtxzRkwu2yGFIo3o20vM3t5bFYjE7FipBefbfpn3106dPHyUmJp533+jRo9WyZUtNnDjxoiUFAOA+vtp6tLikDO8WpeduoqTgLNOKSmBgoGJjY8+7r0aNGqpbt+6f7gcAuK8l245q/PzNchjSsC5R+tfgtvLyoqTgLNPP+gEAeK5vEtP0xPyzR1Ju7xypKUMoKTifqWf9/NGKFSvMjgAAqCLfJqbpsU82y+4wNLRTpF4e2o6Sgj/hiAoAoMp9tz29uKQM6dhAr97WTt6UFJSAogIAqFI/7EjXox8nqMhhaFCHCL12e3tKCkpFUQEAVJllOzM07teScnP7CP2bkoKLoKgAAKrET7sz9PC8eBXaDQ1sF67/3NFePt7shnBhvEMAAJXu56RjGvtRwtmS0jZcbw7rQElBmfAuAQBUqrg9x/XQR/EqsDs0IDZMU++kpKDseKcAACrNyj3H9cCcTSoocqh/m/p6a3hH+VJSUA68WwAAleLn3cd0/68lpW+r+np7eCdKCsqNdwwA4LJbtjPj7Nc9RQ71a11f/xvRSX4+7HJQfk41My0AwPV9/+s8KYV2QwNiw/i6B5eEogIAuGzOTYtf5DB0U7tw/WdYB0oKLglFBQBwWSzZdlRPzN8i+68zzv77duZJwaWjqAAALtniLUf05IKzV0Ee0rEB0+LjsqHqAgAuyZcJh4tLyu2dIykpuKw4ogIAqLDPNqXq6S+2yTCkO7tG6aVb28qLkoLLiCMqAIAKmb8hpbikjOjekJKCSsERFQBAuc1bn6z/W7hdkjSyR7ReuKWNLBZKCi4/igoAoFzmrD2k5xbvkCSN7tVIz93UmpKCSkNRAQCU2fS4/Zry7W5J0gNXxeiZG1tRUlCpKCoAgIsyDENvLt+rqcv2SpLGXdtEf+3XgpKCSkdRAQBckGEYevm73Zoed0CS9FT/Fhp3bVOTU8FTUFQAAKVyOAxN/nqHZq9NliQ9e1NrjbkyxuRU8CQUFQBAiewOQ5O+3KZPNx2WxSL9c3CsRnSPNjsWPAxFBQDwJ4V2h/7y6VZ9tfWovCzS67e315BOkWbHggeiqAAAzmMrsuuxjzfrh50Z8vGy6M07O2pgu3CzY8FDUVQAAMXyC+166KN4xe05Lj8fL00b0Ul9WtU3OxY8GEUFACBJyrUV6f7Zm7T2QKaq+Xrr/Xu76Mpm9cyOBQ9HUQEAKOtMoUbP3KCElNOq6e+jGaO6qltMHbNjARQVAPB0mTk2jZy5QduPWBUU4KM5Y7qrQ1Qts2MBkigqAODR0rLO6O4P1mv/8VzVreGnj8Z0V+uIILNjAcUoKgDgoQ6eyNXdH6zXkdNnFB4coLn3d1eTkJpmxwLOQ1EBAA+0K82qez7coBM5NsXUq6GPxnRTZO3qZscC/oSiAgAeJj75lEbP3CBrfpFahQdpzn3dFBLob3YsoEQUFQDwIKv2HteDc+J1ptCuLtG19eGorgqu5mt2LKBUFBUA8BDfJqbp8fmbVWg3dHXzEL17dydV92M3AOfGOxQAPMCnm1L1ty+2yWFIA9uG6z/DOsjPx8vsWMBFUVQAwM19sOqA/rl0lyRpWJcovTSkrby9LCanAsqGogIAbsowDP1n2V69tXyvJOnBqxtr0oCWslgoKXAdFBUAcEMOh6F/LNmpWWsOSZKe6t9Cj1zThJICl0NRAQA3U1Dk0NOfb9WiLUclSS8OaqN7ejQyNxRQQRQVAHAjeQVFGjs3QSv3HJePl0Wv395egzs2MDsWUGEUFQBwEydzCzR61kZtTT2tar7e+t/dnXRti1CzYwGXhKICAG7g8Kk83Ttjgw4cz1Wt6r6aOaqrOjasbXYs4JKVu6js2rVL8+fP16pVq5ScnKy8vDyFhISoY8eO6t+/v4YOHSp/f6ZiBoCqsicjW/d+uEHp1nxFBAdozphuahoaaHYs4LKwGIZhlGXBhIQEPf300/rll1/Uq1cvdevWTREREapWrZpOnjyp7du3a9WqVbJarXr66ac1fvz4Si8sVqtVwcHBysrKUlAQlyUH4Hk2HTqp+2ZtlDW/SM1Ca2rOmG4KD65mdizggsqz/y7zEZWhQ4fqqaee0ueff65atWqVutzatWv15ptv6t///reeeeaZMocGAJTP8l0ZemRegmxFDnWOrq0PR3ZRrep+ZscCLqsyH1EpLCyUr2/ZL1xVluWnTZumadOm6dChQ5KkNm3a6LnnntOAAQPK9Ds4ogLAU322KVV/+zJRdoeh61qG6p27Oqman7fZsYAyKc/+u8wXeihrScnLyyvz8pGRkXr55ZcVHx+vTZs26brrrtOgQYO0Y8eOssYCAI9iGIbejduvpz7fJrvD0NBOkZp+T2dKCtxWha5I1adPHx05cuRP92/YsEEdOnQo8+vcfPPNuvHGG9WsWTM1b95c//rXv1SzZk2tW7euIrEAwK05HIb+tXSXXv52tyTpod6N9frt7eTrzcUF4b4q9O4OCAhQu3bttGDBAkmSw+HQCy+8oCuvvFI33nhjhYLY7XbNnz9fubm56tGjR4nL2Gw2Wa3W834AwBMUFDk04dMt+uCXg5Kk/7uxlSYNaMWU+HB7FZpHZenSpXrnnXd03333afHixTp06JCSk5O1ZMkS9evXr1yvlZiYqB49eig/P181a9bUwoUL1bp16xKXnTJliiZPnlyRyADgsqz5hRr7UbzW7M+Uj5dFr97WTkM6RZodC6gSZR5MW5JJkybplVdekY+Pj1asWKGePXuW+zUKCgqUkpKirKwsff755/rggw8UFxdXYlmx2Wyy2WzFt61Wq6KiohhMC8BtpWWd0eiZG7U7PVs1/Lz1v7s7q3fzELNjAZekPINpK1RUTp06pfvvv1/Lly/Xa6+9pri4OC1atEivvvqqHnnkkQoHl6S+ffuqSZMmmj59+kWX5awfAO4sKT1bo2ZuUFpWvkIC/TVzVFfFNgg2OxZwySplHpXfi42NVUxMjDZv3qyYmBg98MADWrBggR555BEtXbpUS5curVBw6ex4l98fNQEAT7R2f6Ye/GiTsvOL1CSkhmaN7qaoOtXNjgVUuQoNph07dqxWrlypmJiY4vuGDRumrVu3qqCgoMyvM2nSJK1cuVKHDh1SYmKiJk2apBUrVmjEiBEViQUAbuGrrUc1csYGZecXqUt0bX3xcE9KCjzWJY1RuVRjxozR8uXLlZaWpuDgYLVr104TJ07U9ddfX6bn89UPAHdiGIbeX3VAL31z9vTjAbFh+s+wDgrwZY4UuJdK+eonJSVFDRs2LHOII0eOqEGDBhdc5sMPPyzz6wGAO7M7DL24ZKdmrTkkSRrVs5Gevam1vL04/Riercxf/XTt2lUPPfSQNm7cWOoyWVlZev/99xUbG6svvvjisgQEAHeXX2jXox8nFJeU/7uxlZ6/mZICSOU4orJr1y7985//1PXXX6+AgAB17txZERERCggI0KlTp7Rz507t2LFDnTp10quvvlrhid8AwJOcyi3QA3M2aVPyKfl5e+n1O9rrlvYRZscCnEaZx6hs27ZNbdq0UUFBgb755hutWrVKycnJOnPmjOrVq6eOHTuqf//+io2NrezMxRijAsCVpWTmadSsDTpwPFeBAT56754u6tGkrtmxgEpXKfOoeHt7Kz09XSEhIWrcuLE2btyounXN/UBRVAC4qvjkU3pwziZl5hYoPDhAs0Z3U4uwQLNjAVWiUq6eXKtWLR04cECSdOjQITkcjktLCQAeaum2NA1/f50ycwvUJiJIi8b1oqQApSjzGJWhQ4eqd+/eCg8Pl8ViUZcuXeTtXfIpc+cKDQDgN4Zh6N24A3rlu7OnH/dtFao37+yoGv4VmnsT8Ahl/nS89957GjJkiPbt26fHH39cDzzwgAID+T8AACiLQrtDzy7arvkbUyVx+jFQVuWq8TfccIMkKT4+Xk888QRFBQDKwJpfqEfmJuiXfSfkZZGevam1RveKufgTAVTsWj8zZ8683DkAwC0dPpWn0TM3au+xHFX389bbwzuqT6v6ZscCXAZfjAJAJdmaelpjZm/SiRyb6gf568ORXP0YKC+KCgBUgu+2p2v8gs3KL3SoZVigZo7uqvDgambHAlwORQUALiPDMPTBqoN66dtdMgzpmhYh+u9dnVSTM3uACuGTAwCXSaHdoecW79AnG1IkSXdf0VAv3NxGPt5lnrIKwB9QVADgMjiVW6CH58Vr3YGTsljOXlhwzJUxslg4/Ri4FBQVALhE+47laMzsjUrOzFMNP2+9xZk9wGVDUQGAS7Byz3GN+zhB2flFiqxdTR+O7Mp0+MBlRFEBgAowDENz1ibrH0t2yu4w1CW6tt69p7Pq1fQ3OxrgVigqAFBOhXaHXvhqh+atPzto9rbOkfrXrbHy9yn5+mcAKo6iAgDlcDqvQI/MS9Ca/ZmyWKS/3dBSD17dmEGzQCWhqABAGe0/nqP7Z2/SwRO5quHnral3dtT1rRk0C1QmigoAlMEve0/okXnxsuYXqUGtavpgZBe1Cg8yOxbg9igqAHABhmHoo3XJmvz12UGznaNrazqDZoEqQ1EBgFLYiux6btEOLdiUKkka0rGBXhrSVgG+DJoFqgpFBQBKcMyar7Fz45WQclpeFmkig2YBU1BUAOAPtqSe1kMfbVKG1aagAB+9fVcn9W4eYnYswCNRVADgd76IP6xJCxNVUORQ09Caev/eLoqpV8PsWIDHoqgAgKQiu0MvfbNbM1YflCT1bVVf/xnWXoEBviYnAzwbRQWAxzuVW6BHP0nQ6n2ZkqTH+zTT+D7N5OXFeBTAbBQVAB5td7pVD8zZpNSTZ1Tdz1tv3NFeN8SGmx0LwK8oKgA81nfb0zTh063KK7Arqk41vX9vF7UMYxI3wJlQVAB4HIfD0NTle/XW8r2SpF5N6+q/wzupdg0/k5MB+COKCgCPkpVXqPELNuvnpOOSpDFXxmjSgJby8fYyORmAklBUAHiMHUez9PDcBKWczJO/j5deurWthnaONDsWgAugqADwCF8mHNakLxNlK3Ioqk41vXt3Z7WJCDY7FoCLoKgAcGsFRQ79c+lOzVmbLEm6pkWIpg7roFrVGY8CuAKKCgC3lWHN1yPzEhSffEoS86MAroiiAsAtrT+QqXEfb9aJHJsCA3w0dVgH9WlV3+xYAMqJogLArRiGoRmrD+mlb3bJ7jDUMixQ797dWY24Xg/gkigqANxGXkGRJn6RqK+3HpUkDeoQoSlD2qq6H3/qAFfFpxeAWzhwPEcPz01QUka2fLws+vvAVhrZs5EsFsajAK6MogLA5S3ZdlQTP9+m3AK7QgL99b8RndS1UR2zYwG4DCgqAFyWrciul5bu0uxfTz3uFlNH/x3eUaFBASYnA3C5UFQAuKTUk3l69OMEbT2cJUl65JommnB9c6bCB9wMRQWAy1m2M0MTPt0ia36Rgqv56j/D2uu6lpx6DLgjigoAl1Fkd+i1H5I0Pe6AJKlDVC39966Oiqxd3eRkACqLqcdIp0yZoq5duyowMFChoaEaPHiwkpKSzIwEwEmlZ+XrrvfXF5eUUT0b6dOHelBSADdnalGJi4vTuHHjtG7dOv34448qLCxUv379lJuba2YsAE7ml70nNPCtVdpw6KRq+vvofyM66YVb2sjPh/EogLuzGIZhmB3inOPHjys0NFRxcXG6+uqrL7q81WpVcHCwsrKyFBQUVAUJAVQlu8PQ2z/t1ZvL98owpFbhQfrfiE6KYZZZwKWVZ//tVGNUsrLOjt6vU6fk+Q9sNptsNlvxbavVWiW5AFS9Y9n5mrBgq37Zd0KSdGfXKL1wSxsF+HqbnAxAVXKaouJwODR+/Hj16tVLsbGxJS4zZcoUTZ48uYqTAahqK/cc14RPt+hEToECfL30r8FtNbRzpNmxAJjAab76efjhh/Xtt9/ql19+UWRkyX+QSjqiEhUVxVc/gJsotDv07x/26N24/ZKklmGB+u9dHdU0NNDkZAAuJ5f76ufRRx/VkiVLtHLlylJLiiT5+/vL39+/CpMBqCqpJ/P0+PzN2pxyWpJ09xUN9feBrfmqB/BwphYVwzD02GOPaeHChVqxYoViYmLMjAPAJN8mpunpL7YpO79IgQE+enVoOw1oG252LABOwNSiMm7cOH388cdavHixAgMDlZ6eLkkKDg5WtWrVzIwGoArkF9r14pKdmrc+RZLUsWEtvXVnR0XVYW4UAGeZOkaltMuvz5w5U6NGjbro8zk9GXBd+45l69GPN2t3erYk6eFfr9Xjy7V6ALfnMmNUnGQcL4AqZBiGPtt0WM9/tUNnCu2qV9NPb9zRQVc3DzE7GgAn5BSDaQF4Bmt+of6+cLu+2npUknRVs3r69x3tFRoYYHIyAM6KogKgSmw4eFJPLtiiI6fPyNvLor/0a66xVzeRl1fJXwEDgERRAVDJCu0OvbV8r975eZ8chtSwTnVNvbODOjWsbXY0AC6AogKg0hw8kavxC7Zoa+ppSdJtnSP1wi1tVNOfPz0Ayoa/FgAuu3MDZl/4eofyCuwKCvDRS0Pa6qZ2EWZHA+BiKCoALqtTuQV6ZmGivt1+dl6kKxrX0Rt3dFBELeZGAlB+FBUAl83qfSc04dMtyrDa5ONl0V/7t9ADVzWWNwNmAVQQRQXAJbMV2fXvH/bovZUHJEmN69XQm3d2VNvIYJOTAXB1FBUAl2RPRrbGz9+inWlWSdJd3Rvq7wNbqboff14AXDr+kgCoELvD0IxfDuq1H5JUUORQ7eq+emVoO/VrE2Z2NABuhKICoNxSMvP018+2asOhk5Kka1uE6JWh7RQaxAyzAC4vigqAMjMMQ59sSNU/l+5UXoFdNfy89febWuvOrlGlXmQUAC4FRQVAmRyz5uvpL7ZpRdJxSVK3RnX0+u3t1bBudZOTAXBnFBUAF/X11qN6dvF2nc4rlJ+Pl57q10L3XRnDaccAKh1FBUCpTuUW6NnF27VkW5okKbZBkN64o4Oa1w80ORkAT0FRAVCin5OOaeLn23Qs2yZvL4vGXdtUj13XVL7eXmZHA+BBKCoAzmPNL9RLS3dp/sZUSVLjkBr6zx0d1D6qlrnBAHgkigqAYj8nHdMzXyYqLStfkjS6VyNNvKGlAny9TU4GwFNRVAAoK69Q/1iyU18kHJYkRdetrleGttMVjeuanAyAp6OoAB5u2c4MPbMwUceybbJYpNE9Y/RU/xaq5sdRFADmo6gAHupUboEmf71Di7YclXT2QoKv3tZOXRrVMTkZAPyGogJ4oO+2p+nvi3boRI5NXhbpgasa68nrmzMWBYDToagAHiQzx6bnvtqhpb/Oi9IstKZeva2dOjasbXIyACgZRQXwAIZhaMm2ND3/1Q6dzC2Qt5dFY3s31uN9msnfh6MoAJwXRQVwc0dOn9Fzi7Zr+e5jkqSWYYF67bb2ahsZbHIyALg4igrgpuwOQ3PWHtLr3ycpt8AuX2+LHrmmqcZd21R+PswuC8A1UFQAN7Q73aq/fZGoLamnJUmdo2vr5SFt1Yxr9ABwMRQVwI3kF9r11vK9em/lARU5DAX6++jpAS01oltDeXGlYwAuiKICuIk1+0/omS8TdSgzT5LUv019Tb4lVmHBASYnA4CKo6gALu50XoH+tXSXPos/O/19/SB/Tb4lVjfEhpmcDAAuHUUFcFGGYejrbWn6x9c7dCKnQJJ09xUN9fQNLRUU4GtyOgC4PCgqgAs6eCJXzy3erlV7T0iSmobW1MtD2jL9PQC3Q1EBXEh+oV3TVuzXtLj9KihyyM/bS49c20QPX9OEidsAuCWKCuAiViQd0/Nf7VDyr4Nlr2pWT/8YFKuYejVMTgYAlYeiAji5tKwz+sfXO/Xt9nRJZwfLPndTG93YNkwWC6ccA3BvFBXASRXaHZq1+pD+s2yP8grs8vayaHTPRhp/fXPV9OejC8Az8NcOcEIbD53U3xduV1JGtqSzM8u+OChWrSOCTE4GAFWLogI4kcwcm17+dnfxnCi1q/tq0oBWuq1zJDPLAvBIFBXACRTaHZq7Lllv/LhH2flFkqTh3aL0dP+Wql3Dz+R0AGAeigpgstX7Tmjy1zu0JyNHktQ6PEgvDo5V5+jaJicDAPNRVACTpJ7M00vf7Co+m6d2dV/9tX8L3dm1obz5mgcAJFFUgCp3psCud+P26924/bIVOeRlke65IlpPXt9ctarzNQ8A/B5FBagihmHo2+3p+tfSXTpy+owk6YrGdfTCLW3UMoyzeQCgJBQVoArsTrdq8lc7tfZApiSpQa1q+r+BrTQglknbAOBCKCpAJTqZW6A3l+3R3PUpsjsM+ft4aWzvJhrbu4mq+XFtHgC4GIoKUAlsRXbNXnNIb/+0r/h04wGxYXrmxlaKqlPd5HQA4Dq8zPzlK1eu1M0336yIiAhZLBYtWrTIzDjAJTMMQ98kpqnvG3F66Zvdys4vUqvwIM27v7um3d2ZkgIA5WTqEZXc3Fy1b99e9913n4YMGWJmFOCSbU45pX8t3aVNyackSaGB/vpr/xYa2imS040BoIJMLSoDBgzQgAEDyry8zWaTzWYrvm21WisjFlAuh0/l6dXvkvTV1qOSpABfLz14dRM9dHVj1eDigQBwSVzqr+iUKVM0efJks2MAkqTs/EL9b8V+ffjLQRUUOWSxSEM6Ruqp/i0UFhxgdjwAcAsuVVQmTZqkCRMmFN+2Wq2KiooyMRE8UZHdoQWbUvXGD3uUmVsg6ex8KH8f2FqxDYJNTgcA7sWlioq/v7/8/f3NjgEPZRiGvtuertd+SNKB47mSpJh6NfTMja3Ut1Uo86EAQCVwqaICmGXN/hN65bskbU09LensdXke79NMI7pHy8/H1JPnAMCtUVSAC9hxNEuvfpekuD3HJUnV/bx1/5UxeuDqxgoM8DU5HQC4P1OLSk5Ojvbt21d8++DBg9qyZYvq1Kmjhg0bmpgMni4lM0///jFJi7ecPZPHx8uiu7o31GPXNVNIIF8/AkBVMbWobNq0Sddee23x7XMDZUeOHKlZs2aZlAqe7ESOTf/9aZ/mrU9Wod2QJN3cPkJ/ub65GtWrYXI6APA8phaVa665RoZhmBkBkCTl2Ir0waoDen/lAeUW2CVJVzWrp4k3tORMHgAwEWNU4NHyCoo0Z22ypsft16m8QklSu8hg/e2GlurZtJ7J6QAAFBV4pPxCu+atT9G0Fft0IufsXCiN69XQX/q10I1twzjVGACcBEUFHsVWZNeCjal65+d9yrCevRxDwzrV9USfZhrUIUI+3pxqDADOhKICj1Bod+izTYf135/26mhWviSpQa1qeuy6phraOVK+FBQAcEoUFbi1IrtDCzcf0Vs/7VXqyTOSpPpB/nr02qa6o2uU/H28TU4IALgQigrcUpHdoSXb0vTW8r06cOLsdPf1avrp4WuaakT3hgrwpaAAgCugqMCtFNodWphwRP9bsU+HMvMknZ3ufmzvJrqnR7Sq+/GWBwBXwl9tuIX8Qrs+iz+sd1fs15HTZ7/iqV3dV2OujNGoXjGq6c9bHQBcEX+94dLOFNj18YYUvbdyf/FZPPVq+uvBq2M0onu0alBQAMCl8VccLinHVqSP1ibrg1UHlJl7dh6U8OAAje3dRMO6RjEGBQDcBEUFLiUrr1Cz1hzSjNUHlXXm7EyyUXWq6ZFrmmpIpwacxQMAboaiApeQnpWvmasPat76FOXYiiRJjUNqaNw1TXVLhwjmQQEAN0VRgVPbm5Gt91Ye0KItR4qvZtyifqAeva6pbmwbLm8vproHAHdGUYHTMQxDm5JPaXrcfi3bdaz4/m4xdTS2d2Nd0zxUXhQUAPAIFBU4DYfD0I+7MjQ9br8SUk5LkiwWqX/rMD3Yu7E6NaxtbkAAQJWjqMB0tiK7FiYc0XurDujA8bOzyPp5e2lo5wa6/6rGahJS0+SEAACzUFRgmpO5BfpkQ4pmrTmk49ln50AJCvDR3VdEa1SvRgoNDDA5IQDAbBQVVLmk9GzNXH1QCzcfka3IIensHChjrozRnd0aMossAKAYewRUCYfD0M9JxzRj9UGt3pdZfH/bBsEa3auRbmoXIT8fTjEGAJyPooJKlWMr0uebUjVrzaHiiwR6WaQbYsN0X68YdY6uLYuFM3gAACWjqKBSpJ7M0+w1h7RgY6qyf52gLSjAR8O7NdQ9PaIVWbu6yQkBAK6AooLLxuEw9Mu+E5q7LlnLdmXIcXZ+NjUOqaHRPRtpSKdILhIIACgX9hq4ZKdyC/R5/GHNW59c/PWOJF3VrJ7uuzJGvZuFMEEbAKBCKCqoEMMwtDn1tOauS9aSbWkq+PXsnUB/Hw3p1EB3XxGtZvUDTU4JAHB1FBWUS15BkRZvOaq565K146i1+P42EUG6+4po3dI+gq93AACXDXsUlMnejGzNW5+iL+IPFw+O9fPx0k3twnXPFdHqEFWLs3cAAJcdRQWlyrUVaem2NC3YlKr45FPF90fXra67u0frts6Rql3Dz8SEAAB3R1HBeQzDUELKaX26MVVLth1VboFdkuTtZdF1LUN1zxXRurJpPQbHAgCqBEUFkqQTOTYtTDiiBZtSte9YTvH9MfVq6PYukbqtU6RCg7j2DgCgalFUPJjdYWjlnuNasDFVy3ZlqOjXiU8CfL10Y9twDesSpW4xdRh7AgAwDUXFA+3JyNbCzUe0MOGI0q35xfe3j6qlYV2idHP7cAUG+JqYEACAsygqHuKYNV9fbT2qLxOOaGfab6cV167uq1s7RmpY1yi1CGPeEwCAc6GouLFcW5F+2JmuLxOOaPW+E8VT2vt6W3RNi1AN6dhA17UKlb+Pt7lBAQAoBUXFzRTZHVq9P1OLNh/Rd9vTdabQXvxY5+jaGtyxgW5qG85pxQAAl0BRcQMOx9np7JduS9PX247qeLat+LFGdavr1o6RGtwxQtF1a5iYEgCA8qOouCjDMLT1cJaWbD2qbxLTdDTrt0Gxtav76ub2Ebq1YwNmjAUAuDSKigsxDEOJR7K0dFualmxL05HTZ4ofq+nvo+tb19fAtuHq3SJEvt5eJiYFAODyoKg4OcMwtOOoVUsT07R0W5pSTuYVP1bdz1t9W9XXwHbh6t08RAG+DIoFALgXiooTsjsMbU45pR92ZuiHHek6lPlbOanm660+rUJ1U7twXdMilHICAHBrFBUnkV9o1+p9J/TDjgwt352hEzkFxY8F+HrpupahGtg2Qte2DFF1PzYbAMAzsMcz0em8Av20+5h+2JGhlXuPK6/gt1OJAwN81KdlqPq1CVPv5iGq4c+mAgB4HvZ+VSwlM0/Ld2fohx0Z2nDopOznZmGTFB4coH6t66tfmzB1i6nDgFgAgMejqFSy/EK7Nhw8qRVJx7Ui6ZgOnMg97/GWYYHF5aRNRBCnEgMA8DsUlUqQejJPK/Yc14rdx7Rmf+Z5s8N6e1nUJbq2rm9dX/1ah6lh3eomJgUAwLlRVC4DW5FdGw+e0oqkY/o56Zj2Hz//qElooL+ubRGqa1qEqFezegriysQAAJSJUxSVd955R6+99prS09PVvn17vf322+rWrZvZsUpldxjaedSq1ftPaPW+E9p46KTyCx3Fj3t7WdS5YW1d0zJE1zQPVavwQL7SAQCgAkwvKgsWLNCECRP07rvvqnv37po6dar69++vpKQkhYaGmh1P0tlJ1w6cyNWafSe0el+m1h7IVNaZwvOWCQn01zXNQ3RNi1Bd2ayegqtx1AQAgEtlMQzDuPhilad79+7q2rWr/vvf/0qSHA6HoqKi9Nhjj+lvf/vbBZ9rtVoVHBysrKwsBQUFXdZc6Vn5Wr3vhFbvP6E1+zKVbs0/7/Ga/j66onEd9WxST72a1lPz+jU5agIAQBmUZ/9t6hGVgoICxcfHa9KkScX3eXl5qW/fvlq7du2flrfZbLLZfrsysNVqrZRcM1cf1OSvd553n5+3lzpH11avpnXVs2k9tWsQLB9OHwYAoFKZWlROnDghu92u+vXrn3d//fr1tXv37j8tP2XKFE2ePLnSc8U2CJaXRWrbIFg9m9ZTryb11KVRbaarBwCgipk+RqU8Jk2apAkTJhTftlqtioqKuuy/p2NULW1+rh/jTAAAMJmpRaVevXry9vZWRkbGefdnZGQoLCzsT8v7+/vL39+/0nP5eHspuBpf6wAAYDZT98Z+fn7q3Lmzli9fXnyfw+HQ8uXL1aNHDxOTAQAAZ2D6Vz8TJkzQyJEj1aVLF3Xr1k1Tp05Vbm6uRo8ebXY0AABgMtOLyrBhw3T8+HE999xzSk9PV4cOHfTdd9/9aYAtAADwPKbPo3IpKnMeFQAAUDnKs/9mxCgAAHBaFBUAAOC0KCoAAMBpUVQAAIDToqgAAACnRVEBAABOi6ICAACcFkUFAAA4LYoKAABwWqZPoX8pzk2qa7VaTU4CAADK6tx+uyyT47t0UcnOzpYkRUVFmZwEAACUV3Z2toKDgy+4jEtf68fhcOjo0aMKDAyUxWK5rK9ttVoVFRWl1NRUt7yOkLuvn8Q6ugN3Xz+JdXQH7r5+0uVfR8MwlJ2drYiICHl5XXgUiksfUfHy8lJkZGSl/o6goCC3feNJ7r9+EuvoDtx9/STW0R24+/pJl3cdL3Yk5RwG0wIAAKdFUQEAAE6LolIKf39/Pf/88/L39zc7SqVw9/WTWEd34O7rJ7GO7sDd108ydx1dejAtAABwbxxRAQAATouiAgAAnBZFBQAAOC2KCgAAcFoeXVTeeecdNWrUSAEBAerevbs2bNhwweU/++wztWzZUgEBAWrbtq2++eabKkpaPlOmTFHXrl0VGBio0NBQDR48WElJSRd8zqxZs2SxWM77CQgIqKLE5ffCCy/8KW/Lli0v+BxX2X7nNGrU6E/raLFYNG7cuBKXd/ZtuHLlSt18882KiIiQxWLRokWLznvcMAw999xzCg8PV7Vq1dS3b1/t3bv3oq9b3s9xZbrQOhYWFmrixIlq27atatSooYiICN177706evToBV+zIu/1ynSx7Thq1Kg/5b3hhhsu+rrOsh0vtn4lfSYtFotee+21Ul/T2bZhWfYR+fn5GjdunOrWrauaNWtq6NChysjIuODrVvQzfDEeW1QWLFigCRMm6Pnnn1dCQoLat2+v/v3769ixYyUuv2bNGg0fPlxjxozR5s2bNXjwYA0ePFjbt2+v4uQXFxcXp3HjxmndunX68ccfVVhYqH79+ik3N/eCzwsKClJaWlrxT3JychUlrpg2bdqcl/eXX34pdVlX2n7nbNy48bz1+/HHHyVJt99+e6nPceZtmJubq/bt2+udd94p8fFXX31Vb731lt59912tX79eNWrUUP/+/ZWfn1/qa5b3c1zZLrSOeXl5SkhI0LPPPquEhAR9+eWXSkpK0i233HLR1y3Pe72yXWw7StINN9xwXt5PPvnkgq/pTNvxYuv3+/VKS0vTjBkzZLFYNHTo0Au+rjNtw7LsI5588kl9/fXX+uyzzxQXF6ejR49qyJAhF3zdinyGy8TwUN26dTPGjRtXfNtutxsRERHGlClTSlz+jjvuMAYOHHjefd27dzceeuihSs15ORw7dsyQZMTFxZW6zMyZM43g4OCqC3WJnn/+eaN9+/ZlXt6Vt985TzzxhNGkSRPD4XCU+LgrbUNJxsKFC4tvOxwOIywszHjttdeK7zt9+rTh7+9vfPLJJ6W+Tnk/x1Xpj+tYkg0bNhiSjOTk5FKXKe97vSqVtI4jR440Bg0aVK7XcdbtWJZtOGjQIOO666674DLOvA0N48/7iNOnTxu+vr7GZ599VrzMrl27DEnG2rVrS3yNin6Gy8Ijj6gUFBQoPj5effv2Lb7Py8tLffv21dq1a0t8ztq1a89bXpL69+9f6vLOJCsrS5JUp06dCy6Xk5Oj6OhoRUVFadCgQdqxY0dVxKuwvXv3KiIiQo0bN9aIESOUkpJS6rKuvP2ks+/ZuXPn6r777rvgBThdbRuec/DgQaWnp5+3jYKDg9W9e/dSt1FFPsfOJisrSxaLRbVq1brgcuV5rzuDFStWKDQ0VC1atNDDDz+szMzMUpd15e2YkZGhpUuXasyYMRdd1pm34R/3EfHx8SosLDxvm7Rs2VINGzYsdZtU5DNcVh5ZVE6cOCG73a769eufd3/9+vWVnp5e4nPS09PLtbyzcDgcGj9+vHr16qXY2NhSl2vRooVmzJihxYsXa+7cuXI4HOrZs6cOHz5chWnLrnv37po1a5a+++47TZs2TQcPHtRVV12l7OzsEpd31e13zqJFi3T69GmNGjWq1GVcbRv+3rntUJ5tVJHPsTPJz8/XxIkTNXz48Ate5K2873Wz3XDDDZozZ46WL1+uV155RXFxcRowYIDsdnuJy7vydpw9e7YCAwMv+pWIM2/DkvYR6enp8vPz+1OBvtg+8twyZX1OWbn01ZNxcePGjdP27dsv+n1ojx491KNHj+LbPXv2VKtWrTR9+nS9+OKLlR2z3AYMGFD83+3atVP37t0VHR2tTz/9tEz/d+NqPvzwQw0YMEARERGlLuNq29CTFRYW6o477pBhGJo2bdoFl3W19/qdd95Z/N9t27ZVu3bt1KRJE61YsUJ9+vQxMdnlN2PGDI0YMeKig9adeRuWdR9hJo88olKvXj15e3v/aQRzRkaGwsLCSnxOWFhYuZZ3Bo8++qiWLFmin3/+WZGRkeV6rq+vrzp27Kh9+/ZVUrrLq1atWmrevHmpeV1x+52TnJysZcuW6f777y/X81xpG57bDuXZRhX5HDuDcyUlOTlZP/744wWPppTkYu91Z9O4cWPVq1ev1Lyuuh1XrVqlpKSkcn8uJefZhqXtI8LCwlRQUKDTp0+ft/zF9pHnlinrc8rKI4uKn5+fOnfurOXLlxff53A4tHz58vP+j/T3evTocd7ykvTjjz+WuryZDMPQo48+qoULF+qnn35STExMuV/DbrcrMTFR4eHhlZDw8svJydH+/ftLzetK2++PZs6cqdDQUA0cOLBcz3OlbRgTE6OwsLDztpHVatX69etL3UYV+Ryb7VxJ2bt3r5YtW6a6deuW+zUu9l53NocPH1ZmZmapeV1xO0pnj3J27txZ7du3L/dzzd6GF9tHdO7cWb6+vudtk6SkJKWkpJS6TSryGS5PYI80f/58w9/f35g1a5axc+dO48EHHzRq1aplpKenG4ZhGPfcc4/xt7/9rXj51atXGz4+Psbrr79u7Nq1y3j++ecNX19fIzEx0axVKNXDDz9sBAcHGytWrDDS0tKKf/Ly8oqX+eP6TZ482fj++++N/fv3G/Hx8cadd95pBAQEGDt27DBjFS7qL3/5i7FixQrj4MGDxurVq42+ffsa9erVM44dO2YYhmtvv9+z2+1Gw4YNjYkTJ/7pMVfbhtnZ2cbmzZuNzZs3G5KMN954w9i8eXPxGS8vv/yyUatWLWPx4sXGtm3bjEGDBhkxMTHGmTNnil/juuuuM95+++3i2xf7HFe1C61jQUGBccsttxiRkZHGli1bzvts2my24tf44zpe7L1e1S60jtnZ2cZf//pXY+3atcbBgweNZcuWGZ06dTKaNWtm5OfnF7+GM2/Hi71PDcMwsrKyjOrVqxvTpk0r8TWcfRuWZR8xduxYo2HDhsZPP/1kbNq0yejRo4fRo0eP816nRYsWxpdffll8uyyf4Yrw2KJiGIbx9ttvGw0bNjT8/PyMbt26GevWrSt+rHfv3sbIkSPPW/7TTz81mjdvbvj5+Rlt2rQxli5dWsWJy0ZSiT8zZ84sXuaP6zd+/Pjif4v69esbN954o5GQkFD14cto2LBhRnh4uOHn52c0aNDAGDZsmLFv377ix115+/3e999/b0gykpKS/vSYq23Dn3/+ucT35bl1cDgcxrPPPmvUr1/f8Pf3N/r06fOn9Y6Ojjaef/758+670Oe4ql1oHQ8ePFjqZ/Pnn38ufo0/ruPF3utV7ULrmJeXZ/Tr188ICQkxfH19jejoaOOBBx74U+Fw5u14sfepYRjG9OnTjWrVqhmnT58u8TWcfRuWZR9x5swZ45FHHjFq165tVK9e3bj11luNtLS0P73O759Tls9wRVh+/WUAAABOxyPHqAAAANdAUQEAAE6LogIAAJwWRQUAADgtigoAAHBaFBUAAOC0KCoAAMBpUVQAAIDToqgAAACnRVEBAABOi6ICAACcFkUFgNM4fvy4wsLC9NJLLxXft2bNGvn5+Z13+XgAnoOLEgJwKt98840GDx6sNWvWqEWLFurQoYMGDRqkN954w+xoAExAUQHgdMaNG6dly5apS5cuSkxM1MaNG+Xv7292LAAmoKgAcDpnzpxRbGysUlNTFR8fr7Zt25odCYBJGKMCwOns379fR48elcPh0KFDh8yOA8BEHFEB4FQKCgrUrVs3dejQQS1atNDUqVOVmJio0NBQs6MBMAFFBYBTeeqpp/T5559r69atqlmzpnr37q3g4GAtWbLE7GgATMBXPwCcxooVKzR16lR99NFHCgoKkpeXlz766COtWrVK06ZNMzseABNwRAUAADgtjqgAAACnRVEBAABOi6ICAACcFkUFAAA4LYoKAABwWhQVAADgtCgqAADAaVFUAACA06KoAAAAp0VRAQAATouiAgAAnNb/A6KlmBVGH7EOAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "\n",
    "x = np.arange(0.0, 20.0, 0.1)\n",
    "y = function_1(x)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('f(x)')\n",
    "plt.plot(x,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.1999999999990898\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff_badcase(function_1, 5))\n",
    "print(numerical_diff(function_1, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 편미분\n",
    "\n",
    "$f(x0, x1) = (x0)^2 + (x1)^2$\n",
    "\n",
    "x0 = 3, x1 = 4 일 때 x0 편미분, x1 편미분을 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_2(x):\n",
    "    return x[0]**2 + x[1]**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tmp1(x0):\n",
    "    return x0 * x0 + 4 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def function_tmp2(x1):\n",
    "    return 3 ** 2 + x1 * x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.00000000000378\n",
      "7.999999999999119\n"
     ]
    }
   ],
   "source": [
    "print(numerical_diff(function_tmp1, 3))\n",
    "print(numerical_diff(function_tmp2, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerical_gradient(f, x):\n",
    "    h = 1e-4\n",
    "    grad = np.zeros_like(x)\n",
    "\n",
    "    for idx in range(x.size):\n",
    "        tmp_val = x[idx]\n",
    "        x[idx] = tmp_val + h\n",
    "        fxh1 = f(x)\n",
    "\n",
    "        x[idx] = tmp_val - h\n",
    "        fxh2 = f(x)\n",
    "\n",
    "        grad[idx] = (fxh1 - fxh2) / (2 * h)\n",
    "        x[idx] = tmp_val\n",
    "    \n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 0.])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_gradient(function_2, np.array([3.0, 4.0]))\n",
    "numerical_gradient(function_2, np.array([0.0, 2.0]))\n",
    "numerical_gradient(function_2, np.array([3.0, 0.0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 경사법\n",
    " : 기계학습을 최적화하기 위해 사용함.\n",
    " \n",
    "   현위치에서 기울어진 방향으로 조금씩 이동시키며 기울기를 측정하여 손실함수의 값을 줄어들게 만듦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(f, init_x, lr = 0.01, step_num = 100):\n",
    "    x = init_x\n",
    "\n",
    "    for i in range(step_num):\n",
    "        grad = numerical_gradient(f, x)\n",
    "        x -= lr * grad\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.58983747e+13 -1.29524862e+12]\n",
      "[-2.999994  3.999992]\n"
     ]
    }
   ],
   "source": [
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=10))\n",
    "\n",
    "init_x = np.array([-3.0, 4.0])\n",
    "print(gradient_descent(function_2, init_x=init_x, lr=0.00000001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "import numpy as np\n",
    "from common.functions import softmax, cross_entropy_error\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class simpleNet:\n",
    "    def __init__(self):\n",
    "        self.W = np.random.randn(2,3)\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return np.dot(x, self.W)\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        z = self.predict(x)\n",
    "        y = softmax(z)\n",
    "        loss = cross_entropy_error(y, t)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.68603858 -0.74684455  0.04812626]\n",
      " [ 1.92528321  0.39255156 -0.59877181]]\n",
      "[ 1.32113173 -0.09481033 -0.51001887]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2.1697097660743663"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = simpleNet()\n",
    "print(net.W)\n",
    "\n",
    "x = np.array([0.6, 0.9])\n",
    "p = net.predict(x)\n",
    "print(p)\n",
    "np.argmax(p)\n",
    "\n",
    "t = np.array([0, 0, 1])\n",
    "net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(W):\n",
    "    return net.loss(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.42767722  0.10379592 -0.53147314]\n",
      " [ 0.64151583  0.15569388 -0.79720971]]\n"
     ]
    }
   ],
   "source": [
    "dW = numerical_gradient(f, net.W)\n",
    "print(dW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 알고리즘 구현하기\n",
    "\n",
    "1 단계 : 미니배치\n",
    "2 단계 : 기울기 산출\n",
    "3 단계 : 매개변수 갱신\n",
    "4 단계 : 반복"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.functions import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "class TwoLayerNet:\n",
    "    def __init__(self, input_size, hidden_size, output_size,\n",
    "                 weight_init_std=0.01):\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * np.random.randn(input_size, hidden_size)\n",
    "        self.params['b1'] = np.zeros(hidden_size)\n",
    "        self.params['W2'] = weight_init_std * np.random.randn(hidden_size, output_size)\n",
    "        self.params['b2'] = np.zeros(output_size)\n",
    "\n",
    "    def predict(self, x):\n",
    "        W1, W2 = self.params['W1'], self.params['W2']\n",
    "        b1, b2 = self.params['b1'], self.params['b2']\n",
    "\n",
    "        a1 = np.dot(x, W1) + b1\n",
    "        z1 = sigmoid(a1)\n",
    "        a2 = np.dot(a1, W2) + b2\n",
    "        y = softmax(a2)\n",
    "\n",
    "        return y\n",
    "    \n",
    "    def loss(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        return cross_entropy_error(y, t)\n",
    "    \n",
    "    def accuracy(self, x, t):\n",
    "        y = self.predict(x)\n",
    "        y = np.argmax(y, axis = 1)\n",
    "        t = np.argmax(t, axis = 1)\n",
    "\n",
    "        accuracy = np.sum(y == t) / float(x.shape[0])\n",
    "        return accuracy\n",
    "    \n",
    "    def numerical_gradient(self, x, t):\n",
    "        loss_W = self.loss(x, t)\n",
    "        grads = {}\n",
    "        grads['W1'] = numerical_gradient(loss_W, self.params['W1'])\n",
    "        grads['b1'] = numerical_gradient(loss_W, self.params['b1'])\n",
    "        grads['W2'] = numerical_gradient(loss_W, self.params['W2'])\n",
    "        grads['b2'] = numerical_gradient(loss_W, self.params['b2'])\n",
    "\n",
    "        return grads\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = TwoLayerNet(input_size=784, hidden_size=100, output_size=10)\n",
    "x = np.random.rand(100, 784)\n",
    "y = net.predict(x)\n",
    "print(y)\n",
    "\n",
    "t = np.random.rand(100, 10)\n",
    "\n",
    "grads = net.numerical_gradient(x, t)\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00192726 -0.00995248 -0.00508157 ...  0.01084112 -0.00998404\n",
      "  -0.00979663]\n",
      " [-0.01216128 -0.0088589  -0.00143952 ... -0.00804641 -0.0062289\n",
      "  -0.0024923 ]\n",
      " [-0.00793773 -0.00038934 -0.01037823 ...  0.02831015  0.00933142\n",
      "   0.00039595]\n",
      " ...\n",
      " [ 0.00526808 -0.01018715  0.00260303 ... -0.00161004  0.00835458\n",
      "  -0.00583796]\n",
      " [-0.00677236 -0.00194073 -0.01190517 ...  0.02447219 -0.00982875\n",
      "  -0.00878216]\n",
      " [ 0.00584366  0.02161194  0.00557591 ...  0.00990685 -0.0206291\n",
      "   0.00148726]]\n",
      "[[ 5.04625138e-03  8.30683684e-03 -1.30808552e-03 -5.49545333e-03\n",
      "  -1.68798661e-02 -8.69188988e-03 -3.97108489e-03  3.75111078e-03\n",
      "   3.03515104e-02  2.66555242e-03]\n",
      " [-2.87752875e-03  3.92746834e-03  3.77065994e-03  4.78376343e-03\n",
      "  -1.50720754e-04 -3.07417599e-03  4.02560475e-03 -1.31135199e-02\n",
      "  -6.53517231e-03  1.79801859e-03]\n",
      " [-5.37587992e-03 -4.60423666e-03  1.64842888e-03  9.62500876e-03\n",
      "   1.41168350e-02  1.09178215e-02  4.25276315e-03 -1.43169089e-03\n",
      "   7.52764506e-03  1.79422400e-02]\n",
      " [ 9.30092224e-03  9.75294898e-03 -6.56400222e-03  4.58599691e-04\n",
      "   1.13645085e-02 -4.81938149e-03  1.91283895e-04  3.97232076e-03\n",
      "  -9.68505203e-03 -1.20712704e-02]\n",
      " [-1.05165759e-02 -2.00491529e-02 -1.70625688e-02 -2.31704004e-02\n",
      "  -2.90788454e-03  4.60738461e-03  1.13828665e-02 -1.18931134e-03\n",
      "   8.92730613e-03  5.27753059e-04]\n",
      " [ 2.44265268e-03 -1.93493347e-02 -2.89513602e-03 -9.92154655e-03\n",
      "   4.48111907e-04 -1.45453208e-02  5.68875307e-04  2.07128516e-03\n",
      "  -3.14581346e-03 -9.46690305e-03]\n",
      " [-9.69484966e-03 -1.85523731e-02 -1.04290920e-02 -7.44031739e-03\n",
      "   1.73956574e-03  6.06046388e-04  1.09635437e-03 -1.03481566e-02\n",
      "   1.53115226e-02 -8.88398355e-03]\n",
      " [ 5.80677896e-04 -1.88954049e-04  1.07174680e-02  1.30823694e-02\n",
      "  -7.10921589e-04  3.57265485e-03  3.01411232e-02 -7.46989793e-03\n",
      "  -3.02956800e-03 -1.17367645e-02]\n",
      " [-1.18654565e-03 -6.10694731e-03 -2.02742057e-03  3.33510089e-03\n",
      "  -3.20584073e-03  1.67726359e-02 -3.19601780e-03 -8.93750371e-03\n",
      "   2.20715998e-03 -1.09859995e-02]\n",
      " [ 7.23450047e-03  8.87661530e-03 -9.03577409e-03  9.23843606e-03\n",
      "  -8.73416187e-03 -9.97354223e-03 -5.33251701e-03 -6.54277265e-03\n",
      "  -4.03694540e-03  1.38440528e-03]\n",
      " [ 5.21318643e-03  1.78532080e-02 -7.82216337e-03  2.31635041e-03\n",
      "  -4.58129310e-03 -1.23042348e-03  8.39947126e-03  9.38148653e-04\n",
      "   3.31674783e-03  1.10767914e-02]\n",
      " [ 1.41171455e-02  1.00808861e-02  3.06010735e-03  4.73175920e-03\n",
      "   7.87114358e-04  1.35719256e-02  1.44215360e-03 -4.92309044e-04\n",
      "  -1.30315694e-02  8.79128931e-03]\n",
      " [ 8.53490586e-03 -6.53345913e-03  8.99452876e-04  9.44966187e-03\n",
      "   5.03930612e-03  4.72709195e-03  1.18267291e-02  4.84551631e-04\n",
      "  -1.12633967e-02 -3.05731836e-03]\n",
      " [ 1.30185906e-02 -3.07154171e-03  5.26567322e-03 -1.23545691e-03\n",
      "  -6.92087044e-03 -9.92677496e-04  9.12049294e-03  6.58315050e-04\n",
      "   4.10249773e-03 -1.47076604e-02]\n",
      " [-7.79108750e-03 -1.75981854e-02  1.16665039e-02  4.74437295e-03\n",
      "  -1.27748343e-02  6.30226890e-03  1.56409193e-02 -1.01361458e-02\n",
      "  -1.30906718e-02 -1.19428383e-02]\n",
      " [ 4.06342462e-03 -2.35680447e-03  1.02459642e-02  1.36705796e-02\n",
      "  -5.56095076e-03  2.57352921e-03 -8.16610164e-03  3.45489009e-03\n",
      "   8.91181940e-03  4.31587053e-03]\n",
      " [-1.12198655e-02  1.87109209e-02 -9.69631185e-03 -1.85276010e-02\n",
      "  -3.04551971e-03  6.50165745e-03  1.20437030e-03  1.21316748e-02\n",
      "   3.58342908e-03 -2.45011320e-03]\n",
      " [-3.03750918e-03  7.17011581e-03  1.43024373e-02  9.14803363e-03\n",
      "  -2.33182600e-02  1.59044997e-03 -1.30073487e-02 -1.11876550e-03\n",
      "   1.87410155e-03  1.43845859e-02]\n",
      " [ 4.96947568e-03  4.37765377e-03 -1.09710041e-03 -1.64181457e-02\n",
      "  -6.59585743e-03 -2.80122691e-02  2.89072235e-04 -4.58403296e-03\n",
      "   2.84978377e-02  1.13542924e-02]\n",
      " [-1.83436814e-02 -6.68354482e-03  3.68734879e-03 -1.19914261e-03\n",
      "  -2.92189117e-03 -4.22096673e-03  1.29684915e-02 -1.00553983e-02\n",
      "  -3.65834257e-04  5.36790210e-03]\n",
      " [-2.05000027e-03  2.84780107e-03  1.86631995e-02 -5.01353103e-03\n",
      "  -1.14972468e-03 -2.37654009e-04  9.54712191e-03 -2.41349334e-03\n",
      "  -1.42371094e-03  1.19249232e-03]\n",
      " [-5.98406880e-03  2.98253924e-03 -3.49283110e-03 -1.41733541e-02\n",
      "   1.24966073e-02 -2.54018735e-02 -5.94511144e-03 -3.49265542e-03\n",
      "  -1.91760548e-02  5.62320695e-03]\n",
      " [ 7.00903349e-03  5.24315884e-03 -5.74567569e-03 -1.31762508e-03\n",
      "  -3.03665256e-03 -2.32650186e-03 -8.35315055e-03  2.66861239e-04\n",
      "  -1.36355193e-02 -5.28483468e-03]\n",
      " [-2.42327739e-03  2.14734837e-03 -1.47607460e-02  8.88319941e-04\n",
      "   9.57946512e-04  8.44399312e-03 -5.02194919e-03  2.93655468e-02\n",
      "  -1.38304877e-03  2.43094156e-03]\n",
      " [ 1.62521547e-02 -5.58198733e-03  1.69700464e-02 -5.96279509e-04\n",
      "   2.02119397e-03 -1.31208526e-02 -9.28855914e-03  1.01880703e-02\n",
      "  -1.13730873e-02 -6.89699234e-03]\n",
      " [-7.94100819e-03  4.92529861e-03 -1.59588783e-04  4.99549776e-03\n",
      "  -1.08893892e-02  3.96508952e-03 -1.45610006e-02  1.62787523e-02\n",
      "   1.66045333e-03 -8.99500693e-03]\n",
      " [ 1.52819139e-03  3.45459438e-03 -1.60994020e-02 -2.13721684e-03\n",
      "   2.33451545e-02  5.83846151e-03  2.77758052e-03 -8.88699424e-03\n",
      "  -1.26403462e-02 -1.39152137e-02]\n",
      " [ 1.28153288e-02 -1.31947433e-02 -3.70517799e-03 -3.74275093e-03\n",
      "   3.49262050e-03 -1.09673270e-02 -1.50906917e-02  7.70468009e-03\n",
      "  -6.29275704e-03  1.10804360e-02]\n",
      " [ 5.75092939e-03  6.75535089e-03  1.26495782e-02 -1.46244744e-02\n",
      "  -1.19774632e-02 -4.87715849e-03  1.34532427e-04  1.64306457e-02\n",
      "   1.00283803e-02 -1.27231685e-02]\n",
      " [-3.32330005e-03  7.10746815e-03 -2.33301361e-03  5.67844805e-03\n",
      "   3.97219670e-03 -3.36283307e-03 -2.73387482e-03 -3.07089711e-04\n",
      "  -1.20626420e-02  1.25917090e-02]\n",
      " [-2.47829645e-02  1.27631810e-02 -1.35407752e-02 -3.50552473e-04\n",
      "   1.21411186e-03  2.43107449e-03  4.39581604e-03 -3.14231552e-03\n",
      "  -3.82222511e-03  9.57670730e-03]\n",
      " [ 3.03556152e-03  8.22877852e-03  5.90221288e-03 -6.21556609e-03\n",
      "  -3.59237672e-03 -6.93273745e-03  4.08479812e-03 -2.89170410e-03\n",
      "  -9.49765491e-03  6.63001094e-03]\n",
      " [ 7.14400192e-03  6.35553939e-03 -1.54020561e-02 -7.77566763e-03\n",
      "  -3.97886983e-03 -1.09719213e-02  1.03282126e-02  9.36756257e-03\n",
      "   5.83818656e-03  1.27750244e-02]\n",
      " [ 7.24453057e-04 -5.62921251e-03 -3.36519626e-03  4.69584329e-03\n",
      "   1.73934972e-02 -6.49740469e-03 -1.83828681e-02 -1.77179734e-04\n",
      "  -1.66878179e-02  4.99233776e-03]\n",
      " [-2.37973726e-02 -6.07919788e-03 -1.57059767e-02  1.26485556e-02\n",
      "  -8.16607802e-03  2.26376235e-03 -1.96324495e-03 -2.42572813e-02\n",
      "  -7.22376183e-04 -1.27787368e-02]\n",
      " [ 1.34371076e-04  8.89241431e-03 -9.86812572e-03  3.59855973e-03\n",
      "  -5.04301312e-03  9.24265492e-03  2.18185257e-03  8.41772063e-03\n",
      "   2.32420803e-02 -5.90592998e-03]\n",
      " [-1.08356335e-02 -1.68400589e-02  1.57319301e-02  1.02217045e-02\n",
      "   2.12107387e-03  1.53721940e-02 -4.35151053e-03 -1.01911534e-02\n",
      "   7.56742150e-03 -1.30441026e-04]\n",
      " [ 6.01681201e-03 -1.08571607e-02  1.45538838e-02  9.40503139e-04\n",
      "   8.72821239e-03  8.15776809e-03 -1.03880060e-02  3.95694366e-03\n",
      "   5.38732205e-03  3.33811714e-03]\n",
      " [-2.78969392e-02  7.17973878e-03 -3.51019191e-03 -2.23145734e-02\n",
      "  -6.52586549e-03  5.55789619e-03 -1.01059329e-02  1.59330276e-03\n",
      "  -1.59497533e-03 -1.30859441e-02]\n",
      " [ 2.38499551e-03  2.19062738e-02  2.73430995e-03 -7.89625059e-03\n",
      "   1.91873052e-02  3.93941526e-03  1.02724089e-02  1.25088596e-02\n",
      "   1.06612702e-02  5.56050780e-03]\n",
      " [ 1.54722640e-02 -3.53342198e-04  8.67529718e-03 -3.11317386e-03\n",
      "  -3.84677470e-03 -5.13291956e-03  1.62935899e-02 -1.23014747e-02\n",
      "  -6.53330900e-03 -7.94664648e-03]\n",
      " [-1.37188188e-02 -1.63329495e-02 -3.27088321e-03  5.89226603e-03\n",
      "   1.57727787e-03  2.46838969e-03 -1.22896157e-02 -3.80008468e-03\n",
      "   2.94800816e-04  1.22150099e-02]\n",
      " [-4.35434995e-03  1.22257965e-02 -1.55288507e-02  6.44645111e-03\n",
      "   2.43496179e-03 -9.60240628e-04 -4.92292348e-03  1.66653752e-02\n",
      "  -5.24109673e-03 -7.87807235e-03]\n",
      " [ 2.58926606e-03 -2.41778774e-03  1.17916719e-02 -1.23070706e-03\n",
      "   6.57629883e-03 -6.41663090e-06 -1.32672233e-02 -5.03602448e-03\n",
      "   1.38717014e-03 -7.77482474e-03]\n",
      " [-5.91864249e-03 -1.43992041e-02 -9.37091524e-03 -4.31822741e-03\n",
      "   1.28017204e-02  8.76222748e-03 -1.74600348e-02 -4.82837934e-03\n",
      "  -7.06955944e-03  9.18224349e-04]\n",
      " [-3.58217486e-03  1.19912998e-02 -2.33782568e-02 -2.17516680e-02\n",
      "  -2.04200175e-02  7.09954675e-03  1.53211893e-04  1.01876018e-02\n",
      "  -2.03494762e-03 -1.81828672e-03]\n",
      " [ 1.26030593e-02  1.15310122e-02  1.21704438e-02  6.27501099e-03\n",
      "   5.63691796e-03 -1.38643659e-02 -1.45816668e-03 -7.91884151e-03\n",
      "  -1.80739690e-02 -7.19415366e-03]\n",
      " [ 1.39660658e-02 -1.69228490e-03  1.72905617e-02 -1.21681595e-02\n",
      "  -1.29902994e-03 -7.27011788e-03 -5.44749225e-03  1.46889335e-02\n",
      "   3.74958437e-03 -1.70527986e-02]\n",
      " [ 1.98500065e-03  2.86537389e-02 -3.14384934e-03 -3.09851493e-03\n",
      "   1.55090725e-02  5.55574687e-03  1.19234535e-03 -1.14747191e-02\n",
      "   2.47966286e-02  2.05142218e-03]\n",
      " [-9.41048351e-03  3.12523263e-03 -2.02353447e-02  5.77190336e-03\n",
      "   5.83353232e-03  1.18400856e-02 -6.27266605e-03 -1.11130380e-02\n",
      "   3.57022042e-04  1.23008548e-02]]\n",
      "[[ 0.00192726 -0.00995248 -0.00508157 ...  0.01084112 -0.00998404\n",
      "  -0.00979663]\n",
      " [-0.01216128 -0.0088589  -0.00143952 ... -0.00804641 -0.0062289\n",
      "  -0.0024923 ]\n",
      " [-0.00793773 -0.00038934 -0.01037823 ...  0.02831015  0.00933142\n",
      "   0.00039595]\n",
      " ...\n",
      " [ 0.00526808 -0.01018715  0.00260303 ... -0.00161004  0.00835458\n",
      "  -0.00583796]\n",
      " [-0.00677236 -0.00194073 -0.01190517 ...  0.02447219 -0.00982875\n",
      "  -0.00878216]\n",
      " [ 0.00584366  0.02161194  0.00557591 ...  0.00990685 -0.0206291\n",
      "   0.00148726]]\n",
      "[[ 5.08567413e-03  8.34013020e-03 -1.35302116e-03 -5.44030075e-03\n",
      "  -1.67916442e-02 -8.87904340e-03 -4.21954742e-03  3.94659535e-03\n",
      "   3.03972075e-02  2.68883182e-03]\n",
      " [-2.79260091e-03  3.95537467e-03  3.71373797e-03  4.85332061e-03\n",
      "  -5.99947224e-05 -3.28059514e-03  3.76949393e-03 -1.29095769e-02\n",
      "  -6.49163528e-03  1.79687306e-03]\n",
      " [-5.31265731e-03 -4.59021419e-03  1.60197866e-03  9.69282350e-03\n",
      "   1.42150831e-02  1.07043550e-02  4.00144168e-03 -1.21795476e-03\n",
      "   7.57640654e-03  1.79476725e-02]\n",
      " [ 9.34309997e-03  9.79610788e-03 -6.59926924e-03  5.26781304e-04\n",
      "   1.14440840e-02 -5.01262661e-03 -5.09737869e-05  4.15726271e-03\n",
      "  -9.63527011e-03 -1.20683183e-02]\n",
      " [-1.04788641e-02 -2.00065221e-02 -1.70987737e-02 -2.31069014e-02\n",
      "  -2.80855393e-03  4.40008743e-03  1.11356836e-02 -9.92401819e-04\n",
      "   8.97438578e-03  5.31276778e-04]\n",
      " [ 2.49471004e-03 -1.93136892e-02 -2.93735391e-03 -9.86215376e-03\n",
      "   5.27265628e-04 -1.47378370e-02  3.26870785e-04  2.27266678e-03\n",
      "  -3.10898323e-03 -9.45462562e-03]\n",
      " [-9.60290348e-03 -1.85232089e-02 -1.04700412e-02 -7.37639248e-03\n",
      "   1.82263016e-03  3.97438674e-04  8.41558189e-04 -1.01493280e-02\n",
      "   1.53568956e-02 -8.89193177e-03]\n",
      " [ 6.12457454e-04 -1.57608415e-04  1.06565028e-02  1.31393797e-02\n",
      "  -6.10336636e-04  3.35792828e-03  2.98755461e-02 -7.23524752e-03\n",
      "  -2.96972849e-03 -1.17107060e-02]\n",
      " [-1.12113159e-03 -6.07982407e-03 -2.07975385e-03  3.38693078e-03\n",
      "  -3.11596053e-03  1.65778098e-02 -3.44451205e-03 -8.72828188e-03\n",
      "   2.25094729e-03 -1.09776023e-02]\n",
      " [ 7.31066194e-03  8.91505010e-03 -9.06812325e-03  9.29968199e-03\n",
      "  -8.65305236e-03 -1.01755182e-02 -5.57895332e-03 -6.36512074e-03\n",
      "  -3.99412430e-03  1.38774196e-03]\n",
      " [ 5.25574511e-03  1.79028803e-02 -7.86745279e-03  2.37182811e-03\n",
      "  -4.48371070e-03 -1.41853417e-03  8.15963798e-03  1.11935056e-03\n",
      "   3.36119420e-03  1.10790854e-02]\n",
      " [ 1.41678663e-02  1.01105933e-02  3.00835400e-03  4.79087311e-03\n",
      "   8.88590985e-04  1.33712773e-02  1.18738920e-03 -2.82067254e-04\n",
      "  -1.29899491e-02  8.80557474e-03]\n",
      " [ 8.61464906e-03 -6.50628607e-03  8.48831854e-04  9.53205805e-03\n",
      "   5.11842072e-03  4.52304953e-03  1.15681814e-02  6.97573752e-04\n",
      "  -1.12101103e-02 -3.07884279e-03]\n",
      " [ 1.30701600e-02 -3.02755735e-03  5.24021071e-03 -1.18552834e-03\n",
      "  -6.83191044e-03 -1.18576351e-03  8.89863347e-03  8.41805734e-04\n",
      "   4.13706343e-03 -1.47197512e-02]\n",
      " [-7.76059078e-03 -1.75608390e-02  1.16338177e-02  4.80350973e-03\n",
      "  -1.26794806e-02  6.10148802e-03  1.53923686e-02 -9.93574528e-03\n",
      "  -1.30411742e-02 -1.19330522e-02]\n",
      " [ 4.09851431e-03 -2.31026912e-03  1.02045362e-02  1.37319936e-02\n",
      "  -5.45829079e-03  2.37071982e-03 -8.41307025e-03  3.65106482e-03\n",
      "   8.96552556e-03  4.31149665e-03]\n",
      " [-1.11464701e-02  1.87446054e-02 -9.74675193e-03 -1.84518597e-02\n",
      "  -2.96455767e-03  6.30608051e-03  9.51373272e-04  1.23206527e-02\n",
      "   3.63529351e-03 -2.45572466e-03]\n",
      " [-2.97171988e-03  7.20202619e-03  1.42567973e-02  9.22319695e-03\n",
      "  -2.32370565e-02  1.37765235e-03 -1.32659440e-02 -9.13521168e-04\n",
      "   1.93059617e-03  1.43858133e-02]\n",
      " [ 5.00783166e-03  4.41326067e-03 -1.13400081e-03 -1.63642623e-02\n",
      "  -6.48922873e-03 -2.82170645e-02  6.12346951e-05 -4.39582406e-03\n",
      "   2.85437314e-02  1.13552483e-02]\n",
      " [-1.83014215e-02 -6.65028534e-03  3.64189975e-03 -1.13285451e-03\n",
      "  -2.81539271e-03 -4.42975048e-03  1.27160200e-02 -9.84706464e-03\n",
      "  -3.13745660e-04  5.36587810e-03]\n",
      " [-1.99386433e-03  2.88662588e-03  1.86296269e-02 -4.93934696e-03\n",
      "  -1.06245021e-03 -4.54265159e-04  9.28375439e-03 -2.21269772e-03\n",
      "  -1.36995361e-03  1.19507132e-03]\n",
      " [-5.93184541e-03  3.02065327e-03 -3.53270263e-03 -1.41082029e-02\n",
      "   1.25837767e-02 -2.56031862e-02 -6.19756332e-03 -3.29768275e-03\n",
      "  -1.91272618e-02  5.63041944e-03]\n",
      " [ 7.06724549e-03  5.28753983e-03 -5.78838334e-03 -1.25945326e-03\n",
      "  -2.94986540e-03 -2.52350746e-03 -8.60476525e-03  4.74281099e-04\n",
      "  -1.35928638e-02 -5.29113408e-03]\n",
      " [-2.35571771e-03  2.15692495e-03 -1.48060188e-02  9.36168111e-04\n",
      "   1.07086256e-03  8.23720933e-03 -5.27048700e-03  2.95821769e-02\n",
      "  -1.34297803e-03  2.43693459e-03]\n",
      " [ 1.62892683e-02 -5.55544090e-03  1.69267473e-02 -5.14528186e-04\n",
      "   2.11605954e-03 -1.33259475e-02 -9.54610483e-03  1.03964071e-02\n",
      "  -1.13168716e-02 -6.89588192e-03]\n",
      " [-7.89926498e-03  4.97260738e-03 -1.93826957e-04  5.05921416e-03\n",
      "  -1.07994542e-02  3.76143518e-03 -1.48134668e-02  1.64681165e-02\n",
      "   1.71115636e-03 -8.98741887e-03]\n",
      " [ 1.61083200e-03  3.47758646e-03 -1.61369546e-02 -2.07179311e-03\n",
      "   2.34358317e-02  5.63979876e-03  2.53178726e-03 -8.70219360e-03\n",
      "  -1.26025681e-02 -1.39175174e-02]\n",
      " [ 1.28526729e-02 -1.31598880e-02 -3.74735016e-03 -3.67792978e-03\n",
      "   3.58260458e-03 -1.11664682e-02 -1.53421137e-02  7.90591423e-03\n",
      "  -6.23661937e-03  1.10887950e-02]\n",
      " [ 5.80129045e-03  6.79242776e-03  1.25968006e-02 -1.45735489e-02\n",
      "  -1.18759201e-02 -5.06820242e-03 -1.10676645e-04  1.66355879e-02\n",
      "   1.00634267e-02 -1.27140331e-02]\n",
      " [-3.27715654e-03  7.13500559e-03 -2.37497562e-03  5.74857067e-03\n",
      "   4.06279698e-03 -3.55677777e-03 -2.99054996e-03 -1.04774959e-04\n",
      "  -1.20091401e-02  1.25940703e-02]\n",
      " [-2.47375680e-02  1.28082967e-02 -1.35714564e-02 -3.00539736e-04\n",
      "   1.31622272e-03  2.22165111e-03  4.14673520e-03 -2.94478141e-03\n",
      "  -3.77932403e-03  9.58282170e-03]\n",
      " [ 3.09237397e-03  8.25908139e-03  5.86374768e-03 -6.15843422e-03\n",
      "  -3.49065900e-03 -7.11987394e-03  3.85316578e-03 -2.71940007e-03\n",
      "  -9.46875235e-03  6.64007346e-03]\n",
      " [ 7.21908293e-03  6.37896075e-03 -1.54451895e-02 -7.72030172e-03\n",
      "  -3.88768025e-03 -1.11688508e-02  1.00898390e-02  9.55597356e-03\n",
      "   5.87997325e-03  1.27782053e-02]\n",
      " [ 7.81765959e-04 -5.60881425e-03 -3.41096823e-03  4.76098751e-03\n",
      "   1.74973348e-02 -6.68920789e-03 -1.86250189e-02  2.07170659e-05\n",
      "  -1.66614098e-02  5.00106588e-03]\n",
      " [-2.37561989e-02 -6.04845030e-03 -1.57443128e-02  1.27224506e-02\n",
      "  -8.06304954e-03  2.06512028e-03 -2.21924589e-03 -2.40647362e-02\n",
      "  -6.73394578e-04 -1.27761292e-02]\n",
      " [ 1.67794823e-04  8.93854134e-03 -9.90959116e-03  3.64464454e-03\n",
      "  -4.93164633e-03  9.04813356e-03  1.94208267e-03  8.58537343e-03\n",
      "   2.32925754e-02 -5.88532353e-03]\n",
      " [-1.07919081e-02 -1.67827070e-02  1.56979755e-02  1.02724132e-02\n",
      "   2.21856711e-03  1.51714408e-02 -4.58721838e-03 -9.99456358e-03\n",
      "   7.59492939e-03 -1.33402437e-04]\n",
      " [ 6.08349284e-03 -1.08371404e-02  1.45008425e-02  1.00568389e-03\n",
      "   8.83206016e-03  7.96633726e-03 -1.06234460e-02  4.15033209e-03\n",
      "   5.42575948e-03  3.33047386e-03]\n",
      " [-2.78465371e-02  7.22595907e-03 -3.54950965e-03 -2.22621752e-02\n",
      "  -6.44995093e-03  5.36848997e-03 -1.03335207e-02  1.78737725e-03\n",
      "  -1.55716175e-03 -1.30864556e-02]\n",
      " [ 2.44424007e-03  2.19156617e-02  2.68162944e-03 -7.82509500e-03\n",
      "   1.92810823e-02  3.73979038e-03  1.00153406e-02  1.27285161e-02\n",
      "   1.07050775e-02  5.57285265e-03]\n",
      " [ 1.55282455e-02 -3.27304670e-04  8.61844205e-03 -3.04037718e-03\n",
      "  -3.75681464e-03 -5.32326699e-03  1.60416587e-02 -1.21053133e-02\n",
      "  -6.48269149e-03 -7.93906740e-03]\n",
      " [-1.36880473e-02 -1.62945611e-02 -3.32008552e-03  5.96846300e-03\n",
      "   1.67018209e-03  2.26655686e-03 -1.25457035e-02 -3.60666960e-03\n",
      "   3.60709391e-04  1.22245480e-02]\n",
      " [-4.29311576e-03  1.22771889e-02 -1.55710629e-02  6.49341606e-03\n",
      "   2.52747798e-03 -1.14740012e-03 -5.16320314e-03  1.68518565e-02\n",
      "  -5.20818798e-03 -7.87991885e-03]\n",
      " [ 2.62849446e-03 -2.39952076e-03  1.17560046e-02 -1.16502343e-03\n",
      "   6.68230527e-03 -2.12012722e-04 -1.35194327e-02 -4.83857776e-03\n",
      "   1.44325648e-03 -7.76407043e-03]\n",
      " [-5.83817075e-03 -1.43725671e-02 -9.41147778e-03 -4.25601026e-03\n",
      "   1.28955607e-02  8.56712412e-03 -1.77079153e-02 -4.64732311e-03\n",
      "  -7.02979795e-03  9.17786752e-04]\n",
      " [-3.50749053e-03  1.20250878e-02 -2.34211965e-02 -2.16689033e-02\n",
      "  -2.03388326e-02  6.87296936e-03 -1.24852954e-04  1.03954408e-02\n",
      "  -1.96585113e-03 -1.82006232e-03]\n",
      " [ 1.26525154e-02  1.15823969e-02  1.21306371e-02  6.33674533e-03\n",
      "   5.72282426e-03 -1.40477052e-02 -1.69046269e-03 -7.73620296e-03\n",
      "  -1.80443967e-02 -7.19940398e-03]\n",
      " [ 1.40221975e-02 -1.65857311e-03  1.72468405e-02 -1.21185973e-02\n",
      "  -1.19108062e-03 -7.47881425e-03 -5.69403623e-03  1.49006417e-02\n",
      "   3.79253733e-03 -1.70558532e-02]\n",
      " [ 2.01717778e-03  2.86879249e-02 -3.18782232e-03 -3.03568986e-03\n",
      "   1.56209072e-02  5.34793557e-03  9.43677979e-04 -1.12870598e-02\n",
      "   2.48503955e-02  2.06942473e-03]\n",
      " [-9.37832972e-03  3.15138687e-03 -2.02685396e-02  5.82418665e-03\n",
      "   5.93799728e-03  1.16496010e-02 -6.51082695e-03 -1.09207901e-02\n",
      "   3.93172049e-04  1.23192410e-02]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "train_loss_list = []\n",
    "\n",
    "iters_num = 2\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ['W1', 'b1', 'W2', 'b2']:\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "\n",
    "    print(network.params['W1'])\n",
    "    print(network.params['W2'])\n",
    "\n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from dataset.mnist import load_mnist\n",
    "from two_layer_net import TwoLayerNet\n",
    "import matplotlib.pylab as plt\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, one_hot_label=True)\n",
    "\n",
    "network = TwoLayerNet(input_size=784, hidden_size=50, output_size=10)\n",
    "iters_num = 10\n",
    "train_size = x_train.shape[0]\n",
    "batch_size = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "train_loss_list = []\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "iter_per_epoch = max(train_size / batch_size, 1)\n",
    "\n",
    "for i in range(iters_num):\n",
    "    batch_mask = np.random.choice(train_size, batch_size)\n",
    "    x_batch = x_train[batch_mask]\n",
    "    t_batch = t_train[batch_mask]\n",
    "\n",
    "    grad = network.numerical_gradient(x_batch, t_batch)\n",
    "\n",
    "    for key in ['W1', 'b1', 'W2', 'b2']:\n",
    "        network.params[key] -= learning_rate * grad[key]\n",
    "    \n",
    "    loss = network.loss(x_batch, t_batch)\n",
    "    train_loss_list.append(loss)\n",
    "\n",
    "    if i % iter_per_epoch == 0:\n",
    "        train_acc = network.accuracy(x_train,t_train)\n",
    "        test_acc = network.accuracy(x_test, t_test)\n",
    "        train_acc_list.append(train_acc)\n",
    "        test_acc_list.append(test_acc)\n",
    "\n",
    "plt.plot(np.arange(1, len(train_acc_list)+1), train_acc_list)\n",
    "plt.title(\"train accuracy\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(np.arange(1, len(test_acc_list)+1), test_acc_list)\n",
    "plt.title(\"test accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
