{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"yYBapXccMQpx"},"outputs":[],"source":["%pip install \"unsloth[colab] @ git+https://github.com/unslothai/unsloth.git\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cwTstAXxMgKP"},"outputs":[],"source":["base_model = \"beomi/Llama-3-Open-Ko-8B-Instruct-preview\"\n","\n","kr_dataset = \"/content/drive/MyDrive/korean_commongen/Training/korean_commongen_train_labeled.csv\"\n","kr_validate_dataset = \"/content/drive/MyDrive/korean_commongen/Validation/korean_commongen_validate_labeled.csv\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fvf5BMj8PAy3"},"outputs":[],"source":["from unsloth import FastLanguageModel\n","import torch\n","max_seq_length = 2048\n","dtype = None\n","load_in_8bit = False\n","\n","model, tokenizer = FastLanguageModel.from_pretrained(\n","    model_name = base_model,\n","    max_seq_length = max_seq_length,\n","    dtype = dtype,\n","    load_in_8bit = load_in_8bit,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BXUvUtw_PCT-"},"outputs":[],"source":["model = FastLanguageModel.get_peft_model(\n","    model,\n","    r = 16,\n","    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n","                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n","    lora_alpha = 32,\n","    lora_dropout = 0,\n","    bias = \"none\",\n","    use_gradient_checkpointing = \"unsloth\",\n","    random_state = 1,\n","    use_rslora = False,\n","    loftq_config = None,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ikbRmgD-PEPG"},"outputs":[],"source":["alpaca_prompt = \"\"\"아래는 질문 instruction 과 추가정보를 나타내는 input 입니다. 적절한 response를 생성해주세요.\n","\n","### Instruction:\n","{}\n","\n","### Input:\n","{}\n","\n","### Response:\n","{}\"\"\"\n","\n","EOS_TOKEN = tokenizer.eos_token\n","\n","def formatting_prompts_func(examples):\n","    texts = \"<begin_of_text> \" + examples[\"text\"] + EOS_TOKEN\n","    return { \"text\" : texts, }\n","\n","\n","EOS_TOKEN = tokenizer.eos_token\n","\n","def formatting_prompts_func(examples):\n","    instructions = examples[\"instruction\"]\n","    inputs       = examples[\"input\"]\n","    outputs      = examples[\"output\"]\n","    texts = []\n","    for instruction, input, output in zip(instructions, inputs, outputs):\n","        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n","        texts.append(text)\n","    return { \"text\" : texts, }\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WlLuzSRuPGxu"},"outputs":[],"source":["import pandas as pd\n","from datasets import Dataset\n","\n","df = pd.read_csv(kr_dataset)\n","val_df = pd.read_csv(kr_validate_dataset)\n","\n","train_dataset = Dataset.from_pandas(df)\n","valid_dataset = Dataset.from_pandas(val_df)\n","\n","train_datset = train_dataset.map(formatting_prompts_func, batched=True)\n","valid_dataset = valid_dataset.map(formatting_prompts_func, batched=True)\n","\n","print(len(train_datset))\n","print(len(valid_dataset))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yDom5ompPgxW"},"outputs":[],"source":["from trl import SFTTrainer\n","from transformers import TrainingArguments\n","from unsloth import is_bfloat16_supported\n","\n","trainer = SFTTrainer(\n","    model = model,\n","    tokenizer = tokenizer,\n","    train_dataset = train_dataset,\n","    eval_dataset = valid_dataset,\n","    dataset_text_field = \"text\",\n","    max_seq_length = max_seq_length,\n","    dataset_num_proc = 2,\n","    packing = False,\n","    args = TrainingArguments(\n","        per_device_train_batch_size = 1,\n","        gradient_accumulation_steps = 16,\n","        warmup_steps = 5,\n","        max_steps = 100,\n","        do_eval=True,\n","        evaluation_strategy=\"steps\",\n","        logging_steps=1,\n","        learning_rate = 2e-5,\n","        fp16 = not is_bfloat16_supported(),\n","        bf16 = is_bfloat16_supported(),\n","        optim = \"adamw_8bit\",\n","        weight_decay = 0.01,\n","        lr_scheduler_type = \"cosine\",\n","        seed = 3407,\n","        output_dir = \"outputs\",\n","    ),\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gp1ak5dzP40N"},"outputs":[],"source":["trainer_stats = trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ty7gitxIENTv"},"outputs":[],"source":["import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","df = pd.DataFrame(trainer.state.log_history)\n","\n","train_loss = df ['loss'].dropna()\n","val_loss = df ['eval_loss'].dropna()\n","\n","epochs = range(1, len(train_loss) + 1)\n","\n","plt.figure(figsize=(10, 5))\n","plt.plot(epochs, train_loss, label='Training Loss')\n","plt.plot(epochs, val_loss, label='Validation Loss')\n","plt.xlabel('Epochs')\n","plt.ylabel('Loss')\n","plt.title('Training and Validation Loss')\n","plt.legend()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Gl8fdgW3Etiv"},"outputs":[],"source":["def generate_response(prompt, model):\n","    prompt = alpaca_prompt.format(prompt, \"개념 세트: 카페 이름, 대, 이겼\", \"\")\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"친절한 챗봇으로서 상대방의 요청에 최대한 자세하고 친절하게 답하자. 모든 대답은 한국어(Korean)으로 대답해줘.\"},\n","        {\"role\": \"user\", \"content\": f\"{prompt}\"},\n","    ]\n","\n","    input_ids = tokenizer.apply_chat_template(\n","        messages,\n","        add_generation_prompt=True,\n","        return_tensors=\"pt\"\n","    ).to(model.device)\n","\n","    terminators = [\n","        tokenizer.eos_token_id,\n","        tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n","    ]\n","\n","    outputs = model.generate(\n","        input_ids,\n","        max_new_tokens=512,\n","        eos_token_id=terminators,\n","        do_sample=True,\n","        temperature=0.1,\n","        top_p=0.9,\n","    )\n","\n","    response = outputs[0][input_ids.shape[-1]:]\n","    return tokenizer.decode(response, skip_special_tokens=True)\n","\n","\n","instruction = \"주어진 개념 세트를 이용하여 문장을 생성하세요.\"\n","\n","generate_response(instruction, model)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Bku5g0hO52GM"},"outputs":[],"source":["FINETUNED_MODEL = \"drive/MyDrive/llama3_alpaca_Instruct\"\n","\n","trainer.model.save_pretrained(FINETUNED_MODEL)\n","tokenizer.save_pretrained(FINETUNED_MODEL)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyNpOCC6tTNZEirc5BAasZcd","gpuType":"L4","machine_shape":"hm","mount_file_id":"12k0g8Avcl2_DMAxgF3MDVKRTh4Bqs8mg","private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
